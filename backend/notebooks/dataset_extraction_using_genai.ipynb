{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>\n",
      "PaSa: An LLM Agent for Comprehensive Academic Paper Search\n",
      "\n",
      "=>\n",
      "Yichen He∗1\n",
      "Guanhua Huang∗1\n",
      "Peiyuan Feng1\n",
      "Yuan Lin†1\n",
      "\n",
      "=>\n",
      "Yuchen Zhang1\n",
      "Hang Li1\n",
      "Weinan E2\n",
      "\n",
      "=>\n",
      "1ByteDance Research\n",
      "2Peking University\n",
      "\n",
      "=>\n",
      "{hyc,huangguanhua,fpy,linyuan.0}@bytedance.com,\n",
      "{zhangyuchen.zyc,lihang.lh}@bytedance.com, weinan@math.pku.edu.cn\n",
      "\n",
      "=>\n",
      "Demo: https://pasa-agent.ai\n",
      "\n",
      "=>\n",
      "Paper Search\n",
      "\n",
      "=>\n",
      "Abstract\n",
      "\n",
      "=>\n",
      "We introduce PaSa, an advanced Paper Search\n",
      "agent powered by large language models. PaSa\n",
      "can autonomously make a series of decisions,\n",
      "including invoking search tools, reading pa-\n",
      "pers, and selecting relevant references, to ul-\n",
      "timately obtain comprehensive and accurate\n",
      "results for complex scholarly queries. We op-\n",
      "timize PaSa using reinforcement learning with\n",
      "a synthetic dataset, AutoScholarQuery, which\n",
      "includes 35k fine-grained academic queries and\n",
      "corresponding papers sourced from top-tier AI\n",
      "conference publications. Additionally, we de-\n",
      "velop RealScholarQuery, a benchmark collect-\n",
      "ing real-world academic queries to assess PaSa\n",
      "performance in more realistic scenarios. De-\n",
      "spite being trained on synthetic data, PaSa sig-\n",
      "nificantly outperforms existing baselines on\n",
      "RealScholarQuery, including Google, Google\n",
      "Scholar, Google with GPT-4 for paraphrased\n",
      "queries, chatGPT (search-enabled GPT-4o),\n",
      "GPT-o1, and PaSa-GPT-4o (PaSa implemented\n",
      "by prompting GPT-4o). Notably, PaSa-7B sur-\n",
      "passes the best Google-based baseline, Google\n",
      "with GPT-4o, by 37.78% in recall@20 and\n",
      "39.90% in recall@50. It also exceeds PaSa-\n",
      "GPT-4o by 30.36% in recall and 4.25% in pre-\n",
      "cision. Model, datasets, and code are available\n",
      "at https://github.com/bytedance/pasa.\n",
      "\n",
      "=>\n",
      "∗Equal contribution.\n",
      "†Corresponding author.\n",
      "\n",
      "=>\n",
      "1\n",
      "Introduction\n",
      "\n",
      "=>\n",
      "Academic paper search lies at the core of research\n",
      "yet represents a particularly challenging informa-\n",
      "tion retrieval task. It requires long-tail special-\n",
      "ized knowledge, comprehensive survey-level cover-\n",
      "age, and the ability to address fine-grained queries.\n",
      "For instance, consider the query: \"Which stud-\n",
      "ies have focused on non-stationary reinforcement\n",
      "learning using value-based methods, specifically\n",
      "UCB-based algorithms?\" While widely used aca-\n",
      "demic search systems like Google Scholar are effec-\n",
      "tive for general queries, they often fall short when\n",
      "addressing these complex queries (Gusenbauer and\n",
      "Haddaway, 2020). Consequently, researchers fre-\n",
      "quently spend substantial time conducting litera-\n",
      "ture surveys (Kingsley et al., 2011; Gusenbauer\n",
      "and Haddaway, 2021).\n",
      "\n",
      "=>\n",
      "The advancements in large language models\n",
      "(LLMs) (OpenAI, 2023; Anthropic, 2024; Gemini,\n",
      "2023; Yang et al., 2024) have inspired numerous\n",
      "studies leveraging LLMs to enhance information\n",
      "retrieval, particularly by refining or reformulating\n",
      "search queries to improve retrieval quality (Alaofi\n",
      "et al., 2023; Li et al., 2023; Ma et al., 2023; Peng\n",
      "et al., 2024). In academic search, however, the\n",
      "process goes beyond simple retrieval. Human re-\n",
      "searchers not only use search tools, but also engage\n",
      "in deeper activities, such as reading relevant papers\n",
      "and checking citations, to perform comprehensive\n",
      "and accurate literature surveys.\n",
      "\n",
      "=>\n",
      "1\n",
      "\n",
      "=>\n",
      "arXiv:2501.10120v1  [cs.IR]  17 Jan 2025\n",
      "\n",
      "=>\n",
      "Paper Queue\n",
      "Crawler\n",
      "User Query\n",
      "Selector\n",
      "\n",
      "=>\n",
      "User Query\n",
      "\n",
      "=>\n",
      "Select / Drop\n",
      "\n",
      "=>\n",
      "[Search]\n",
      "\n",
      "=>\n",
      "[Expand]\n",
      "[Stop]\n",
      "\n",
      "=>\n",
      "Figure 1: Architecture of PaSa. The system consists of two LLM agents, Crawler and Selector. The Crawler\n",
      "processes the user query and can access papers from the paper queue. It can autonomously invoke the search tool,\n",
      "expand citations, or stop processing of the current paper. All papers collected by the Crawler are appended to the\n",
      "paper queue. The Selector reads each paper in the paper queue to determine whether it meets the criteria specified in\n",
      "the user query.\n",
      "\n",
      "=>\n",
      "In this paper, we introduce PaSa, a novel paper\n",
      "search agent designed to mimic human behavior\n",
      "for comprehensive and accurate academic paper\n",
      "searches. As illustrated in Figure 1, PaSa con-\n",
      "sists of two LLM agents: the Crawler and the Se-\n",
      "lector. For a given user query, the Crawler can\n",
      "autonomously collect relevant papers by utilizing\n",
      "search tools or extracting citations from the current\n",
      "paper, which are then added to a growing paper\n",
      "queue. The Crawler iteratively processes each pa-\n",
      "per in the paper queue, navigating citation networks\n",
      "to discover increasingly relevant papers. The Selec-\n",
      "tor carefully reads each paper in the paper queue to\n",
      "determine whether it meets the requirements of the\n",
      "user query. We optimize PaSa within the AGILE, a\n",
      "reinforcement learning (RL) framework for LLM\n",
      "agents (Feng et al., 2024).\n",
      "Effective training requires high-quality academic\n",
      "search data. Fortunately, human scientists have al-\n",
      "ready created a vast amount of high-quality aca-\n",
      "demic papers, which contain extensive surveys on\n",
      "a wide range of research topics. We build a syn-\n",
      "thetic but high-quality academic search dataset,\n",
      "AutoScholarQuery, which collects fine-grained\n",
      "scholar queries and their corresponding relevant\n",
      "papers from the related work sections of papers\n",
      "published at ICLR 2023 1, ICML 2023 2, NeurIPS\n",
      "2023 3, ACL 2024 4, and CVPR 2024 5.\n",
      "Au-\n",
      "toScholarQuery includes 33,511 / 1,000 / 1,000\n",
      "query-paper pairs in the training / development /\n",
      "test split.\n",
      "\n",
      "=>\n",
      "1https://iclr.cc/Conferences/2023\n",
      "2https://icml.cc/Conferences/2023\n",
      "3https://neurips.cc/Conferences/2023\n",
      "4https://2024.aclweb.org/\n",
      "5https://cvpr.thecvf.com/Conferences/2024\n",
      "\n",
      "=>\n",
      "Although AutoScholarQuery only provides\n",
      "query and paper answers, without demonstrating\n",
      "the path by which scientists collect the papers, we\n",
      "can utilize them to perform RL training to improve\n",
      "PaSa. In addition, we design a new session-level\n",
      "PPO (Proximal Policy Optimization (Schulman\n",
      "et al., 2017)) training method to address the unique\n",
      "challenges of the paper search task: 1) sparse re-\n",
      "ward: The papers in AutoScholarQuery are col-\n",
      "lected via citations, making it a smaller subset of\n",
      "the actual qualified paper set. 2) long trajectories:\n",
      "The complete trajectory of the Crawler may involve\n",
      "hundreds of papers, which is too long to directly\n",
      "input into the LLM context.\n",
      "\n",
      "=>\n",
      "To evaluate PaSa, besides the test set of Au-\n",
      "toScholarQuery, we also develop a benchmark, Re-\n",
      "alScholarQuery. It contains 50 real-world academic\n",
      "queries with annotated relevant papers, to assess\n",
      "PaSa in real-world scenarios. We compare PaSa\n",
      "with several baselines including Google, Google\n",
      "Scholar, Google paired with GPT-4o for para-\n",
      "phrased queries, chatGPT (search-enabled GPT-\n",
      "4o), GPT-o1 and PaSa-GPT-4o (PaSa agent real-\n",
      "ized by prompting GPT-4o). Our experiments show\n",
      "that PaSa-7b significantly outperforms all baselines.\n",
      "Specifically, for AutoScholarQuery test set, PaSa-\n",
      "7b achieves a 34.05% improvement in Recall@20\n",
      "and a 39.36% improvement in Recall@50 com-\n",
      "pared to Google with GPT-4o, the strongest Google-\n",
      "based baseline. PaSa-7b surpasses PaSa-GPT-4o\n",
      "by 11.12% in recall, with similar precision. For\n",
      "RealScholarQuery, PaSa-7b outperforms Google\n",
      "with GPT-4o by 37.78% in Recall@20 and 39.90%\n",
      "in Recall@50. PaSa-7b surpasses PaSa-GPT-4o by\n",
      "30.36% in recall and 4.25% in precision.\n",
      "\n",
      "=>\n",
      "2\n",
      "\n",
      "=>\n",
      "The main contributions of this paper are summa-\n",
      "rized as follows:\n",
      "\n",
      "=>\n",
      "• We introduce PaSa, a comprehensive and accu-\n",
      "rate paper search agent that can autonomously\n",
      "use online search tools, read entire papers, and\n",
      "navigate citation networks.\n",
      "\n",
      "=>\n",
      "• We develop two high-quality datasets for com-\n",
      "plex academic search, AutoScholarQuery and\n",
      "RealScholarQuery.\n",
      "\n",
      "=>\n",
      "• Although PaSa is trained solely on synthetic\n",
      "data, it achieves remarkable real-world perfor-\n",
      "mance. Experiments demonstrate that PaSa,\n",
      "built on 7B LLM, significantly outperforms\n",
      "all baselines, including GPT-4 agent, Google-\n",
      "based search, and chatGPT.\n",
      "\n",
      "=>\n",
      "2\n",
      "Related Work\n",
      "\n",
      "=>\n",
      "LLMs in Scientific Discovery\n",
      "LLMs have been\n",
      "applied across various stages of scientific discov-\n",
      "ery (Van Noorden and Perkel, 2023; Lu et al., 2024;\n",
      "Messeri and Crockett, 2024; Liao et al., 2024), such\n",
      "as brainstorming ideas (Girotra et al., 2023; Wang\n",
      "et al., 2024a; Baek et al., 2024), designing exper-\n",
      "iments (M. Bran et al., 2024), writing code (Xu\n",
      "et al., 2022), and generating research papers (Shao\n",
      "et al., 2024; Agarwal et al., 2024; Wang et al.,\n",
      "2024b). One of the most fundamental yet criti-\n",
      "cal stages in research is conducting academic sur-\n",
      "veys. Despite its importance, current tools like\n",
      "Google Scholar are often insufficient, leading re-\n",
      "searchers to spend considerable time on literature\n",
      "review tasks (Kingsley et al., 2011; Gusenbauer\n",
      "and Haddaway, 2021, 2020). This challenge moti-\n",
      "vates us to develop PaSa, an LLM agent designed\n",
      "to autonomously and comprehensively assist re-\n",
      "searchers in collecting relevant research papers for\n",
      "complex scholarly queries.\n",
      "\n",
      "=>\n",
      "LLM Agents\n",
      "LLM Agents combine LLMs with\n",
      "memory, tool use, and planning, enabling them to\n",
      "perform more complex tasks such as personal copi-\n",
      "lots (Stratton, 2024), travel planning (Gundawar\n",
      "et al., 2024), web operations (Deng et al., 2024),\n",
      "software development (Qian et al., 2023), and sci-\n",
      "entific experimentation (Bran et al., 2023). In ad-\n",
      "dition to realizing LLM Agents through prompt\n",
      "engineering (Park et al., 2023; Yao et al., 2023;\n",
      "Shinn et al., 2024; Chen et al., 2023), recent re-\n",
      "search has focused on optimizing and training these\n",
      "agents (Feng et al., 2024; Putta et al., 2024; Liu\n",
      "\n",
      "=>\n",
      "et al., 2023). Among these efforts, AGILE (Feng\n",
      "et al., 2024), a reinforcement learning framework\n",
      "for LLM agents, allows the joint optimization of all\n",
      "agent skills in an end-to-end manner. In our work,\n",
      "we adopt the AGILE framework to implement PaSa.\n",
      "Specifically, we design a novel session-level PPO\n",
      "algorithm to address the unique challenges of the\n",
      "paper search task, including sparse rewards and\n",
      "long trajectories.\n",
      "\n",
      "=>\n",
      "3\n",
      "Datasets\n",
      "\n",
      "=>\n",
      "3.1\n",
      "AutoScholarQuery\n",
      "\n",
      "=>\n",
      "AutoScholarQuery is a synthetic but high-quality\n",
      "dataset of academic queries and related papers,\n",
      "specifically curated for the AI field.\n",
      "To construct AutoScholarQuery, we began by\n",
      "collecting all papers published at ICLR 2023,\n",
      "ICML 2023, NeurIPS 2023, ACL 2024, and CVPR\n",
      "2024. For the Related Work section of each paper,\n",
      "we prompted GPT-4o (Hurst et al., 2024) to gener-\n",
      "ate scholarly queries, where the answers to these\n",
      "queries correspond to the references cited in the\n",
      "Related Work section. The prompt used is shown\n",
      "in Appendix E.1. For each query, we retained only\n",
      "the papers that could be retrieved on arXiv6, using\n",
      "their arxiv_id as the unique article identifier in the\n",
      "dataset. We adopt the publication date of the source\n",
      "paper as the query date. During both training and\n",
      "testing, we only considered papers published prior\n",
      "to the query date.\n",
      "The final AutoScholarQuery dataset comprises\n",
      "33,551, 1,000, and 1,000 instances in the train-\n",
      "ing, development, and testing splits, respectively.\n",
      "Each instance consists of a query, the associated\n",
      "paper set, and the query date, with queries in each\n",
      "split derived from distinct source papers. Table 1\n",
      "provides illustrative examples from AutoScholar-\n",
      "Query, while additional dataset statistics are sum-\n",
      "marized in Table 2.\n",
      "To evaluate the quality of AutoScholarQuery,\n",
      "we sampled 100 query-paper pairs and assessed\n",
      "the rationality and relevance of each query and\n",
      "the corresponding paper. A qualified query should\n",
      "be meaningful and unambiguous. A qualified pa-\n",
      "per should match the requirements of the scholarly\n",
      "query. The author manually reviewed each pair,\n",
      "determining that 94.0% of the queries were qual-\n",
      "ified. Among these qualified queries, 93.7% had\n",
      "corresponding papers that were deemed relevant\n",
      "and appropriate.\n",
      "\n",
      "=>\n",
      "6https://arxiv.org/\n",
      "\n",
      "=>\n",
      "3\n",
      "\n",
      "=>\n",
      "Query: Could you provide me some studies that proposed hierarchical neural models to capture spatiotemporal features in sign\n",
      "videos?\n",
      "Query Date: 2023-05-02\n",
      "Answer Papers:\n",
      "[1] TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation\n",
      "[2] Sign Language Translation with Hierarchical Spatio-Temporal Graph Neural Network\n",
      "Source: SLTUnet: A Simple Unified Model for Sign Language Translation, ICLR 2023\n",
      "Query: Which studies have focused on nonstationary RL using value-based methods, specifically Upper Confidence Bound (UCB)\n",
      "based algorithms?\n",
      "Query Date: 2023-08-10\n",
      "Answer Papers:\n",
      "[1] Reinforcement Learning for Non-Stationary Markov Decision Processes: The Blessing of (More) Optimism\n",
      "[2] Efficient Learning in Non-Stationary Linear Markov Decision Processes\n",
      "[3] Nonstationary Reinforcement Learning with Linear Function Approximation\n",
      "Source: Provably Efficient Algorithm for Nonstationary Low-Rank MDPs, NeurIPS 2023\n",
      "Query: Which studies have been conducted in long-form text generation, specifically in story generation?\n",
      "Query Date: 2024-01-26\n",
      "Answer Papers:\n",
      "[1] Strategies for Structuring Story Generation\n",
      "[2] MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models\n",
      "Source: ProxyQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models, ACL 2024\n",
      "\n",
      "=>\n",
      "Table 1: Examples of queries and corresponding papers in AutoScholarQuery.\n",
      "\n",
      "=>\n",
      "Conference\n",
      "|P|\n",
      "|Q|\n",
      "Ans(/Q)\n",
      "Ans-50\n",
      "Ans-90\n",
      "\n",
      "=>\n",
      "ICLR 2023\n",
      "888\n",
      "5204\n",
      "2.46\n",
      "2.0\n",
      "5.0\n",
      "ICML 2023\n",
      "981\n",
      "5743\n",
      "2.37\n",
      "2.0\n",
      "5.0\n",
      "NeurIPS 2023\n",
      "1948\n",
      "11761\n",
      "2.59\n",
      "2.0\n",
      "5.0\n",
      "CVPR 2024\n",
      "1336\n",
      "9528\n",
      "2.94\n",
      "2.0\n",
      "6.0\n",
      "ACL 2024\n",
      "485\n",
      "3315\n",
      "2.16\n",
      "2.0\n",
      "4.0\n",
      "\n",
      "=>\n",
      "Table 2: Statistics of AutoScholarQuery. |P| and |Q|\n",
      "represent the total number of papers and queries col-\n",
      "lected for each conference. Ans(/Q) denotes the aver-\n",
      "age number of answer papers per query. Ans-50 and\n",
      "Ans-90 refers to the 50th and 90th percentiles of answer\n",
      "paper counts per query.\n",
      "\n",
      "=>\n",
      "3.2\n",
      "RealScholarQuery\n",
      "\n",
      "=>\n",
      "To evaluate PaSa in more realistic scenarios, we\n",
      "constructed RealScholarQuery, a test dataset con-\n",
      "sisting of 50 real-world research queries. After\n",
      "launching the demo of PaSa, we invited several AI\n",
      "researchers to use the system. From the queries\n",
      "they provided, we randomly sampled a subset of\n",
      "queries and manually filtered out overly broad top-\n",
      "ics (e.g., \"multi-modal large language models,\"\n",
      "\"video generation\"). Ultimately, we collected 50\n",
      "fine-grained and realistic queries.\n",
      "For each query, we first manually gathered rele-\n",
      "vant papers. Subsequently, we used multiple meth-\n",
      "ods to retrieve additional papers, including PaSa,\n",
      "Google, Google Scholar, ChatGPT (search-enabled\n",
      "GPT-4o), and Google paired with GPT-4o for para-\n",
      "phrased queries. The results from these methods\n",
      "were aggregated into a pool of candidate papers.\n",
      "Finally, professional annotators reviewed all can-\n",
      "didate papers for each query, selecting those that\n",
      "\n",
      "=>\n",
      "met the specific requirements of the query to create\n",
      "the final set of relevant papers. The query date of\n",
      "all instances in RealScholarQuery is 2024-10-01.\n",
      "Table 12 in Appendix D provides examples from\n",
      "RealScholarQuery.\n",
      "\n",
      "=>\n",
      "The annotators included professors from the De-\n",
      "partment of Computer Science at a top-tier univer-\n",
      "sity in China. On average, each query required the\n",
      "annotators to review 76 candidate papers. Given\n",
      "the high cost of the annotations, we completed this\n",
      "process for only 50 instances.\n",
      "\n",
      "=>\n",
      "4\n",
      "Methodology\n",
      "\n",
      "=>\n",
      "4.1\n",
      "Overview\n",
      "\n",
      "=>\n",
      "As illustrated in Figure 1, the PaSa system consists\n",
      "of two LLM agents: Crawler and Selector. The\n",
      "crawler reads the user’s query, generates multiple\n",
      "search queries, and retrieves relevant papers. The\n",
      "retrieved papers are added to a paper queue. The\n",
      "Crawler further processes each paper in the paper\n",
      "queue to identify key citations worth exploring fur-\n",
      "ther, appending any newly relevant papers to the\n",
      "paper list. The selector conducts a thorough review\n",
      "of each paper in the paper list to assess whether it\n",
      "fulfills the user’s query requirements.\n",
      "\n",
      "=>\n",
      "In summary, the Crawler is designed to maxi-\n",
      "mize the recall of relevant papers, whereas the Se-\n",
      "lector emphasizes precision in identifying papers\n",
      "that meet the user’s needs.\n",
      "\n",
      "=>\n",
      "4\n",
      "\n",
      "=>\n",
      "Is there any works that analyze the scaling law of the multi-module models, such as video-text, image-text models.\n",
      "\n",
      "=>\n",
      "[Search]Analysis of scaling \n",
      "law in video-text models\n",
      "[Search]Scaling laws in \n",
      "multi-modal AI models\n",
      "\n",
      "=>\n",
      "[Search]Image-text \n",
      "model scaling laws research\n",
      "[Search]Survey papers on \n",
      "scaling law of multi-module models\n",
      "\n",
      "=>\n",
      "[Stop]\n",
      "\n",
      "=>\n",
      "Neural Scaling \n",
      "Laws for Embodied \n",
      "AI\n",
      "\n",
      "=>\n",
      "…\n",
      "Scaling Law \n",
      "Hypothesis for \n",
      "Multimodal Model\n",
      "\n",
      "=>\n",
      "Scaling Laws for \n",
      "Generative Mixed-Modal \n",
      "Language Models\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "[Expand]1 Introduction\n",
      "[Expand]…\n",
      "[Expand]3 Empirical approach \n",
      "Research paper meta analysis\n",
      "\n",
      "=>\n",
      "[Expand]4 Results 4.1 Scaling Laws \n",
      "for Robot Foundation Models\n",
      "\n",
      "=>\n",
      "[Stop]\n",
      "\n",
      "=>\n",
      "Foundation models in robotics: \n",
      "Applications, challenges, and \n",
      "the future\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "[Expand]II Foundation \n",
      "Models Background       \n",
      "II-D Multimodal Vision-\n",
      "Language Models (VLMs)\n",
      "Scaling language-image \n",
      "pre-training via masking\n",
      "\n",
      "=>\n",
      "[Expand]IV Perception \n",
      "IV-A Open-Vocabulary \n",
      "Object Detection and 3D \n",
      "Classification\n",
      "\n",
      "=>\n",
      "[Stop]\n",
      "\n",
      "=>\n",
      "Simple open-\n",
      "vocabulary \n",
      "object detection \n",
      "with vision \n",
      "transformers\n",
      "\n",
      "=>\n",
      "Foundation \n",
      "models in \n",
      "robotics: \n",
      "Applications, \n",
      "challenges, and \n",
      "the future\n",
      "[Stop]\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "Crawler\n",
      "Selector Select\n",
      "Selector Drop\n",
      "\n",
      "=>\n",
      "…\n",
      "\n",
      "=>\n",
      "Figure 2: An example of the PaSa workflow. The Crawler runs multiple [Search] using diverse and complementary\n",
      "queries. In addition, the Crawler can evaluate the long-term value of its actions. Notably, it discovers many relevant\n",
      "papers as it explores deeper on the citation network, even when intermediate papers along the path do not align with\n",
      "the user query.\n",
      "\n",
      "=>\n",
      "Name\n",
      "Implementation\n",
      "\n",
      "=>\n",
      "Generate a search query and invoke\n",
      "[Search]\n",
      "the search tool. Append all resulting\n",
      "papers to the paper queue.\n",
      "\n",
      "=>\n",
      "Generate a subsection name, then\n",
      "[Expand]\n",
      "add all referenced papers in the sub-\n",
      "section to the paper queue.\n",
      "\n",
      "=>\n",
      "[Stop]\n",
      "Reset the context to the user query and\n",
      "the next paper in the paper queue.\n",
      "\n",
      "=>\n",
      "Table 3: Functions of the Crawler.\n",
      "\n",
      "=>\n",
      "4.2\n",
      "Crawler\n",
      "\n",
      "=>\n",
      "In RL terminology, the Crawler performs a token-\n",
      "level Markov Decision Process (MDP). The ac-\n",
      "tion space A corresponds to the LLM’s vocabulary,\n",
      "where each token represents an action. The LLM\n",
      "functions as the policy model. The agent’s state is\n",
      "defined by the current LLM context and the paper\n",
      "queue. The Crawler operates with three registered\n",
      "functions, as outlined in Table 3. When an ac-\n",
      "tion matches a function name, the corresponding\n",
      "function is executed, further modifying the agent’s\n",
      "state.\n",
      "For example, as Figure 2 shows, the agent begins\n",
      "by receiving a user query, incorporating it into its\n",
      "context, and initiating actions. If the token gener-\n",
      "ated is [Search], the LLM continues to generate a\n",
      "search query, and the agent invokes a search tool to\n",
      "retrieve papers, which are then added to the paper\n",
      "list. If the token is [Expand], the LLM continues\n",
      "to extract a subsection name from the current pa-\n",
      "\n",
      "=>\n",
      "per in its context. The agent subsequently uses a\n",
      "parsing tool to extract all referenced papers within\n",
      "that subsection, adding them to the paper list. If\n",
      "the token is [Stop], the agent resets its context to\n",
      "the user query and information of the next paper\n",
      "in the paper queue. This information includes the\n",
      "title, abstract, and an outline of all sections and\n",
      "subsections.\n",
      "The training process for the Crawler comprises\n",
      "two stages. In the first stage, we generate trajec-\n",
      "tories for a small subset of the training data and\n",
      "then perform imitation learning (see Appendix A.1\n",
      "for details). In the second stage, reinforcement\n",
      "learning is applied. The details of the RL training\n",
      "implementation are described below.\n",
      "\n",
      "=>\n",
      "Reward Design\n",
      "We conduct RL training on the\n",
      "AutoScholarQuery training set, where each in-\n",
      "stance consists of a query q and a corresponding\n",
      "paper set P. Starting with a query q, the Crawler\n",
      "generates a trajectory τ = (s1, a1, · · · , sT , aT ). At\n",
      "each time step t, we denote the current paper queue\n",
      "as Qt. Upon taking action at, the Crawler appends\n",
      "a set of new papers (p1, p2, · · · , pnt) to the paper\n",
      "queue. If at = [Stop], the set is empty.\n",
      "The reward of executing action at in state st is\n",
      "defined as\n",
      "\n",
      "=>\n",
      "r(st, at) = α ×\n",
      "\n",
      "=>\n",
      "nt\n",
      "X\n",
      "\n",
      "=>\n",
      "i=1\n",
      "I(q, pi, t) −c(at),\n",
      "(1)\n",
      "\n",
      "=>\n",
      "where I(q, pi, t) = 1 if pi matches the query q and\n",
      "is not already in Qt, and I(q, pi, t) = 0 otherwise.\n",
      "\n",
      "=>\n",
      "5\n",
      "\n",
      "=>\n",
      "Here, α is a reward coefficient, and c(at) is the cost\n",
      "of action at.\n",
      "The indicator function I(q, pi, t) can be deter-\n",
      "mined by checking if pi belongs to P −Qt. How-\n",
      "ever, it is important to note that the AutoScholar-\n",
      "Query may only include a subset of the ground-\n",
      "truth papers, as citations often emphasize a limited\n",
      "number of key references. If the Crawler receives\n",
      "rewards solely based on matching papers in Au-\n",
      "toScholarQuery, this could lead to sparse rewards\n",
      "during training. To mitigate this, we use the Selec-\n",
      "tor as an auxiliary reward model for the Crawler.\n",
      "The revised definition of I(q, pi, t) is:\n",
      "\n",
      "=>\n",
      "I(q, pi, t) =\n",
      "\n",
      "=>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=>\n",
      "\n",
      "\n",
      "\n",
      "=>\n",
      "1,\n",
      "if (Selector(q, pi) = 1 or pi ∈P)\n",
      "and pi /∈Qt,\n",
      "0,\n",
      "otherwise.\n",
      "(2)\n",
      "\n",
      "=>\n",
      "Here Selector(q, pi) = 1 if paper pi is identified\n",
      "as correct to meet the query q by the Selector, and\n",
      "Selector(q, pi) = 0 otherwise.\n",
      "\n",
      "=>\n",
      "RL Training\n",
      "A key challenge in training the\n",
      "Crawler with RL is the significant time required\n",
      "to sample a complete trajectory for a given query.\n",
      "This is due to each [Search] or [Expand] action\n",
      "adding multiple papers to the paper list, resulting\n",
      "in hundreds or even thousands of papers in the final\n",
      "paper queue.\n",
      "To address this issue, we define a session as a\n",
      "sub-trajectory that begins with a session’s initial\n",
      "state and ends with the [Stop] action. We iden-\n",
      "tify two types of session initial states: Sq, which\n",
      "includes only a query, and Sq+p, which consists of\n",
      "both a query and a paper.\n",
      "Formally,\n",
      "we\n",
      "model\n",
      "the\n",
      "Crawler\n",
      "as\n",
      "a\n",
      "policy πθ(at|st).\n",
      "We partition the entire\n",
      "trajectory\n",
      "τ\n",
      "into\n",
      "a\n",
      "sequence\n",
      "of\n",
      "sessions:\n",
      "(τt1:t2−1, τt2:t3−1, · · · ).\n",
      "Each\n",
      "session\n",
      "is\n",
      "τti:ti+1−1\n",
      "=\n",
      "(sti, ati, · · · , sti+1−1, ati+1−1),\n",
      "where the initial state sti is either belonging to\n",
      "type Sq or Sq+p, and the final action ati+1−1 is\n",
      "[STOP].\n",
      "Sampling such a sub-trajectory from these ses-\n",
      "sion initial states is computationally efficient. Dur-\n",
      "ing the PPO training, at time step t ∈[ti, ti+1),\n",
      "we estimate the return in the session using Monte\n",
      "Carlo sampling:\n",
      "\n",
      "=>\n",
      "ˆRt\n",
      "=\n",
      "\n",
      "=>\n",
      "ti+1−1−t\n",
      "X\n",
      "\n",
      "=>\n",
      "k=0\n",
      "γk\n",
      "0\n",
      "\n",
      "=>\n",
      "\u0014\n",
      "r(st+k, at+k)\n",
      "(3)\n",
      "\n",
      "=>\n",
      "+γ1\n",
      "\n",
      "=>\n",
      "nt+k\n",
      "X\n",
      "\n",
      "=>\n",
      "j=1\n",
      "ˆVϕ(Sq+pj) −β · log πθ(at|st)\n",
      "\n",
      "=>\n",
      "πsft(at|st)\n",
      "\n",
      "=>\n",
      "\u0015\n",
      "\n",
      "=>\n",
      "Here, γ0 is the in-session discount factor, and\n",
      "γ1 is the across-session discount factor.\n",
      "ˆVϕ(·)\n",
      "is the value function model to approximate the\n",
      "state value. After executing at+k, the paper queue\n",
      "is updated to include the newly found papers\n",
      "(p1, p2, · · · , pnt+k). Since the Crawler will subse-\n",
      "quently initiate new sessions to process these addi-\n",
      "tional papers, their associated reward-to-go should\n",
      "be incorporated into the return estimate. In addi-\n",
      "tion, we include a per-token KL penalty term from\n",
      "the learned policy πθ to the initial policy πsft ob-\n",
      "tained through imitation learning at each token to\n",
      "mitigate over-optimization. This term is scaled by\n",
      "the coefficient β.\n",
      "Then the advantage function can be approxi-\n",
      "mated by\n",
      "\n",
      "=>\n",
      "ˆA(st, at)\n",
      "=\n",
      "ˆRt −ˆVϕ(st).\n",
      "(4)\n",
      "\n",
      "=>\n",
      "Finally, the policy and value objectives can be\n",
      "given by\n",
      "\n",
      "=>\n",
      "Lpolicy(θ) =Eτ′∼πold\n",
      "θ\n",
      "\n",
      "=>\n",
      "\"\n",
      "\n",
      "=>\n",
      "min\n",
      "\u0012 πθ(at|st)\n",
      "\n",
      "=>\n",
      "πold\n",
      "θ (at|st)\n",
      "ˆA(st, at),\n",
      "(5)\n",
      "\n",
      "=>\n",
      "clip\n",
      "\u0010 πθ(at|st)\n",
      "\n",
      "=>\n",
      "πold\n",
      "θ (at|st), 1 −ϵ, 1 + ϵ\n",
      "\u0011\n",
      "ˆA(st, at)\n",
      "\u0013#\n",
      "\n",
      "=>\n",
      "and\n",
      "\n",
      "=>\n",
      "Lvalue(ϕ) =\n",
      "Eτ′∼πold\n",
      "θ\n",
      "\n",
      "=>\n",
      "\"\n",
      "\n",
      "=>\n",
      "max\n",
      "\u0012\u0010\n",
      "ˆRt −ˆVϕ(st)\n",
      "\u00112\n",
      ",\n",
      "(6)\n",
      "\n",
      "=>\n",
      "\u0010\n",
      "ˆRt −ˆV clip\n",
      "ϕ\n",
      "(st)\n",
      "\u00112\u0013#\n",
      "\n",
      "=>\n",
      ",\n",
      "\n",
      "=>\n",
      "respectively, where\n",
      "\n",
      "=>\n",
      "ˆV clip\n",
      "ϕ\n",
      "(st) =\n",
      "clip\n",
      "\u0010\n",
      "ˆVϕ(st), V old\n",
      "ϕ (st) −ϵ, V old\n",
      "ϕ (st) + ϵ\n",
      "\u0011\n",
      ". (7)\n",
      "\n",
      "=>\n",
      "Here, πold\n",
      "θ\n",
      "and V old\n",
      "ϕ\n",
      "is used for sampling and τ ′ is\n",
      "session trajectory. We then combine these into the\n",
      "unified RL loss:\n",
      "\n",
      "=>\n",
      "LRL(θ, ϕ) = Lpolicy(θ) + η · Lvalue(ϕ)\n",
      "(8)\n",
      "\n",
      "=>\n",
      "where η is the coefficient of the value objective.\n",
      "\n",
      "=>\n",
      "4.3\n",
      "Selector\n",
      "\n",
      "=>\n",
      "The Selector is an LLM agent that takes two inputs:\n",
      "a scholar query and a research paper (including its\n",
      "title and abstract). It generates two outputs: (1) a\n",
      "single decision token d, either \"True\" or \"False\",\n",
      "indicating whether the paper satisfies the query,\n",
      "\n",
      "=>\n",
      "6\n",
      "\n",
      "=>\n",
      "and (2) a rationale r = (r1, r2, ..., rm) containing\n",
      "m tokens that support this decision. The rationale\n",
      "serves two purposes: enhancing decision accuracy\n",
      "by jointly training the model to generate decisions\n",
      "and explanations, and improving user trust by pro-\n",
      "viding the reasoning in PaSa application.\n",
      "To optimize training efficiency for the Crawler,\n",
      "the decision token is presented before the ratio-\n",
      "nale, allowing the Selector to act as a single-token\n",
      "reward model during the Crawler training. Addi-\n",
      "tionally, the token probability of the decision token\n",
      "can be used to rank search results. At last, as shown\n",
      "in Table 7, the order of the decision and rationale\n",
      "does not affect the Selector’s performance.\n",
      "We perform imitation learning to optimize the\n",
      "Selector. See Appendix B for training data collec-\n",
      "tion and training details.\n",
      "\n",
      "=>\n",
      "5\n",
      "Experiments\n",
      "\n",
      "=>\n",
      "5.1\n",
      "Experimental Setting\n",
      "\n",
      "=>\n",
      "We sequentially trained the Selector and Crawler,\n",
      "both based on the Qwen2.5-7b (Yang et al., 2024),\n",
      "to develop the final agent, referred to as PaSa-7b.\n",
      "\n",
      "=>\n",
      "Selector\n",
      "The Selector was fine-tuned using the\n",
      "training dataset described in Appendix B. We con-\n",
      "ducted supervised fine-tuning for one epoch with\n",
      "a learning rate of 1e-5 and a batch size of 4. The\n",
      "training runs on 8 NVIDIA-H100 GPUs.\n",
      "\n",
      "=>\n",
      "Crawler\n",
      "The training process involves two\n",
      "stages. First, we perform imitation learning for\n",
      "1 epoch on 12,989 training data with a learning\n",
      "rate of 1e-5 and batch size of 4 per device, using\n",
      "8 NVIDIA H100 GPUs. In the second stage, we\n",
      "apply PPO training. To ensure stability, we first\n",
      "freeze the policy model and train the value model,\n",
      "followed by co-training both the policy and value\n",
      "models. The hyperparameters used during the train-\n",
      "ing process are listed in the Table 4.\n",
      "During imitation learning, the model encoun-\n",
      "ters 5,000 queries, while during the RL training\n",
      "phase, the model processes a total of 16,000 queries.\n",
      "For more details please refer to Appendix A.1 for\n",
      "the imitation learning data construction and Ap-\n",
      "pendix A.2 for the PPO training data sampling.\n",
      "\n",
      "=>\n",
      "Implementation of [Search]\n",
      "This function uti-\n",
      "lizes the LLM to predict a query based on the\n",
      "context, and then calls Google7 with the param-\n",
      "eters site:arxiv.org and before:query_date,\n",
      "\n",
      "=>\n",
      "7Accessed via the Google Search API provided by https:\n",
      "//serper.dev.\n",
      "\n",
      "=>\n",
      "Name\n",
      "Value\n",
      "\n",
      "=>\n",
      "α\n",
      "(Equation 1)\n",
      "1.5\n",
      "c([Search])\n",
      "(Equation 1)\n",
      "0.1\n",
      "c([Expand])\n",
      "(Equation 1)\n",
      "0.1\n",
      "c([Stop])\n",
      "(Equation 1)\n",
      "0.0\n",
      "γ0\n",
      "(Equation 3)\n",
      "1.0\n",
      "γ1\n",
      "(Equation 3)\n",
      "0.1\n",
      "β\n",
      "(Equation 3)\n",
      "0.1\n",
      "ϵ\n",
      "(Equation 5, Equation 6)\n",
      "0.2\n",
      "η\n",
      "(Equation 8)\n",
      "10\n",
      "learning rate\n",
      "1e-6\n",
      "epoch per step\n",
      "2\n",
      "forward batch size\n",
      "1\n",
      "accumulate batch size\n",
      "16\n",
      "NVIDIA H100 GPU\n",
      "16\n",
      "policy freezing step\n",
      "50\n",
      "total step\n",
      "250\n",
      "\n",
      "=>\n",
      "Table 4: The hyperparameters used in PPO training.\n",
      "\n",
      "=>\n",
      "restricting search results by source and publication\n",
      "time.\n",
      "\n",
      "=>\n",
      "Paper Management\n",
      "We developed a database to\n",
      "manage and restore research papers. PaSa retrieves\n",
      "paper information from the database. If no match-\n",
      "ing record is found, we use ar5iv8 to obtain the full\n",
      "paper content, including citations, and then parse\n",
      "this data and store it in the database.\n",
      "\n",
      "=>\n",
      "5.2\n",
      "Baselines and Evaluation\n",
      "\n",
      "=>\n",
      "We evaluate our paper search agent on both the test\n",
      "set of AutoScholarQuery and RealScholarQuery.\n",
      "We compare PaSa-7b against the following base-\n",
      "lines:\n",
      "\n",
      "=>\n",
      "• Google. We use Google to search the query\n",
      "directly, with the same parameter settings in\n",
      "Section 5.1.\n",
      "\n",
      "=>\n",
      "• Google Scholar. Queries are submitted di-\n",
      "rectly to Google Scholar7, with the same pa-\n",
      "rameter settings in Section 5.1.\n",
      "\n",
      "=>\n",
      "• Google with GPT-4o. We first employ GPT-\n",
      "4o to paraphrase the scholar query. The para-\n",
      "phrased query is then searched on Google.\n",
      "\n",
      "=>\n",
      "• ChatGPT. We submit the scholar query to\n",
      "ChatGPT9, powered by search-enabled GPT-\n",
      "4o. Due to the need for manual query submis-\n",
      "\n",
      "=>\n",
      "8https://ar5iv.org/\n",
      "9https://chatgpt.com\n",
      "\n",
      "=>\n",
      "7\n",
      "\n",
      "=>\n",
      "Method\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "Recall@100\n",
      "Recall@50\n",
      "Recall@20\n",
      "\n",
      "=>\n",
      "Google\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2015\n",
      "0.1891\n",
      "0.1568\n",
      "Google Scholar\n",
      "-\n",
      "-\n",
      "-\n",
      "0.1130\n",
      "0.0970\n",
      "0.0609\n",
      "Google with GPT-4o\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2683\n",
      "0.2450\n",
      "0.1921\n",
      "ChatGPT\n",
      "-\n",
      "0.0507\n",
      "0.3046\n",
      "-\n",
      "-\n",
      "-\n",
      "GPT-o1\n",
      "-\n",
      "0.0413\n",
      "0.1925\n",
      "-\n",
      "-\n",
      "-\n",
      "PaSa-GPT-4o\n",
      "0.7565\n",
      "0.1457\n",
      "0.3873\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "=>\n",
      "PaSa-7b\n",
      "0.7931\n",
      "0.1448\n",
      "0.4834\n",
      "0.6947\n",
      "0.6334\n",
      "0.5301\n",
      "PaSa-7b-ensemble\n",
      "0.8265\n",
      "0.1410\n",
      "0.4985\n",
      "0.7099\n",
      "0.6386\n",
      "0.5326\n",
      "\n",
      "=>\n",
      "Table 5: Results on AutoScholarQuery test set.\n",
      "\n",
      "=>\n",
      "Method\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "Recall@100\n",
      "Recall@50\n",
      "Recall@20\n",
      "\n",
      "=>\n",
      "Google\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2535\n",
      "0.2342\n",
      "0.1834\n",
      "Google Scholar\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2809\n",
      "0.2155\n",
      "0.1514\n",
      "Google with GPT-4o\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2946\n",
      "0.2573\n",
      "0.2020\n",
      "ChatGPT\n",
      "-\n",
      "0.2280\n",
      "0.2007\n",
      "-\n",
      "-\n",
      "-\n",
      "GPT-o1\n",
      "-\n",
      "0.058\n",
      "0.0134\n",
      "-\n",
      "-\n",
      "-\n",
      "PaSa-GPT-4o\n",
      "0.5494\n",
      "0.4721\n",
      "0.3075\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "=>\n",
      "PaSa-7b\n",
      "0.7071\n",
      "0.5146\n",
      "0.6111\n",
      "0.6929\n",
      "0.6563\n",
      "0.5798\n",
      "PaSa-7b-ensemble\n",
      "0.7503\n",
      "0.4938\n",
      "0.6488\n",
      "0.7281\n",
      "0.6877\n",
      "0.5986\n",
      "\n",
      "=>\n",
      "Table 6: Results on RealScholarQuery.\n",
      "\n",
      "=>\n",
      "sion, we evaluate only 100 randomly sampled\n",
      "instances from the AutoScholarQuery test set.\n",
      "\n",
      "=>\n",
      "• GPT-o1.\n",
      "Prompt GPT-o1 to process the\n",
      "scholar query.\n",
      "\n",
      "=>\n",
      "• PaSa-GPT-4o. Prompt GPT-4o within the\n",
      "PaSa framework.\n",
      "It can perform multiple\n",
      "searches, paper reading, and citation network\n",
      "crawling.\n",
      "\n",
      "=>\n",
      "We carefully designed prompts for all baselines\n",
      "and they are shown in Appendix E.1.\n",
      "As shown in Figure 2, the crawling process of\n",
      "PaSa can be visualized as a paper tree. In practice,\n",
      "considering the computational expense, we limit\n",
      "the Crawler’s exploration depth (starting from the\n",
      "user query) to three for both PaSa-7b and PaSa-\n",
      "GPT-4o.\n",
      "For Google-based baselines, we evaluate recall\n",
      "using Recall@20, Recall@50, and Recall@100\n",
      "metrics for the top-20, top-50, and top-100 search\n",
      "results, respectively. For other baselines, we assess\n",
      "precision and recall for the final retrieved papers.\n",
      "Additionally, we compare the crawler’s recall be-\n",
      "tween PaSa-GPT-4o and PaSa-7b.\n",
      "\n",
      "=>\n",
      "5.3\n",
      "Main results\n",
      "\n",
      "=>\n",
      "As shown in Table 5, PaSa-7b outperforms all base-\n",
      "lines on AutoScholarQuery test set. Specifically,\n",
      "\n",
      "=>\n",
      "compared to the strongest baseline, PaSa-GPT-4o,\n",
      "PaSa-7b demonstrates a 9.64% improvement in\n",
      "recall with comparable precision. Moreover, the re-\n",
      "call of the Crawler in PaSa-7b is 3.66% higher than\n",
      "that in PaSa-GPT-4o. When compared to the best\n",
      "Google-based baseline, Google with GPT-4o, PaSa-\n",
      "7b achieves an improvement of 33.80%, 38.83%\n",
      "and 42.64% in Recall@20, Recall@50 and Re-\n",
      "call@100, respectively.\n",
      "\n",
      "=>\n",
      "We observe that using multiple ensembles of\n",
      "Crawler during inference can improve performance.\n",
      "Specifically, running Crawler twice during infer-\n",
      "ence increased the Crawler recall by 3.34% on Au-\n",
      "toScholarQuery, leading to the final recall improve-\n",
      "ment by 1.51%, with precision remaining similar.\n",
      "\n",
      "=>\n",
      "To evaluate PaSa in a more realistic setting, we\n",
      "assess its effectiveness on RealScholarQuery. As\n",
      "illustrated in Table 6, PaSa-7b exhibits a greater\n",
      "advantage in real-world academic search scenar-\n",
      "ios. Compared to PaSa-GPT-4o, PaSa-7b achieves\n",
      "improvements of 30.36% in recall and 4.25% in\n",
      "precision. Against the best Google-based baseline\n",
      "on RealScholarQuery, Google with GPT-4o, PaSa-\n",
      "7b outperforms Google by 37.78%, 39.90%, and\n",
      "39.83% in recall@20, recall@50 and recall@100,\n",
      "respectively. Additionally, the PaSa-7b-ensemble\n",
      "further enhances crawler recall by 4.32%, contribut-\n",
      "ing to an overall 3.52% improvement in the recall\n",
      "\n",
      "=>\n",
      "8\n",
      "\n",
      "=>\n",
      "of the entire agent system.\n",
      "As both the final decision-maker and auxiliary\n",
      "reward model in RL training for the Crawler, the\n",
      "performance of the Selector is crucial. To evalu-\n",
      "ate its effectiveness, we collected a dataset of 200\n",
      "query-paper pairs, annotating whether each paper\n",
      "meets the query’s requirements. This dataset serves\n",
      "as the benchmark for evaluating the Selector (see\n",
      "Appendix C for details). We then compared our\n",
      "Selector against GPT-4o (Hurst et al., 2024) and\n",
      "Qwen-2.5-7b (Yang et al., 2024), as shown in Ta-\n",
      "ble 7. The results show that our Selector achieves\n",
      "an F1 score of 85%, outperforming GPT-4o by\n",
      "5% and Qwen-2.5-7b by 30%. Additionally, when\n",
      "compared to a setting where reasoning precedes\n",
      "decision token generation, the performance is com-\n",
      "parable. Lastly, the Selector’s precision reaches\n",
      "95%, confirming its effectiveness as an auxiliary\n",
      "reward model for the Crawler RL training.\n",
      "\n",
      "=>\n",
      "Method\n",
      "Precision\n",
      "Recall\n",
      "F1\n",
      "\n",
      "=>\n",
      "GPT-4o\n",
      "0.96\n",
      "0.69\n",
      "0.80\n",
      "Qwen-2.5-7b\n",
      "1.0\n",
      "0.38\n",
      "0.55\n",
      "PaSa-7b-Selector\n",
      "0.95\n",
      "0.78\n",
      "0.85\n",
      "PaSa-7b-Selector (Reason First)\n",
      "0.94\n",
      "0.76\n",
      "0.84\n",
      "\n",
      "=>\n",
      "Table 7: Selector Evaluation.\n",
      "\n",
      "=>\n",
      "5.4\n",
      "Ablation study\n",
      "\n",
      "=>\n",
      "We perform ablation studies in Table 8 to evaluate\n",
      "the individual contributions of exploring citation\n",
      "networks, RL training, and using the Selector as the\n",
      "reward model. The results indicate that removing\n",
      "the [Expand] action from the Crawler leads to a\n",
      "significant drop in the recall: a decrease of 22.98%\n",
      "on AutoScholarQuery and 32.21% on RealScholar-\n",
      "Query. Furthermore, RL training enhances recall\n",
      "by 6.24% on AutoScholarQuery and 19.96% on\n",
      "RealScholarQuery. The RL training curves are de-\n",
      "picted in Figure 3, where the training curves show\n",
      "a steady increase in return with the training steps,\n",
      "eventually converging after 200 steps. Finally, re-\n",
      "moving the Selector as an auxiliary reward model\n",
      "results in a 3.76% recall drop on AutoScholarQuery\n",
      "and a 9.63% drop on RealScholarQuery.\n",
      "We investigate how to control agent behavior by\n",
      "adjusting the rewards in RL training. Experiments\n",
      "are conducted with varying reward coefficients α in\n",
      "Equation 1, and results are presented in Table 9. We\n",
      "report two metrics: crawler recall and crawler ac-\n",
      "tion. The crawler action refers to the total number\n",
      "of [Search] and [Expand] actions throughout the\n",
      "\n",
      "=>\n",
      "Crawler’s entire trajectory. As the reward increases,\n",
      "both crawler recall and crawler action increase, sug-\n",
      "gesting that adjusting rewards in RL training can\n",
      "effectively influence PaSa’s behavior.\n",
      "\n",
      "=>\n",
      "Figure 3: Return and value function loss curves during\n",
      "the PPO training process. The smoothing method of\n",
      "the curve in the figures is the exponential moving av-\n",
      "erage(EMA) formula that aligns with the one used in\n",
      "TensorBoard, and the smoothing weight is set to 0.95.\n",
      "\n",
      "=>\n",
      "6\n",
      "Conclusion\n",
      "\n",
      "=>\n",
      "In this paper, we introduce PaSa, a novel paper\n",
      "search agent designed to provide comprehensive\n",
      "and accurate results for complex academic queries.\n",
      "PaSa is implemented within the AGILE, a rein-\n",
      "forcement learning framework for LLM agents.\n",
      "To train PaSa, we developed AutoScholarQuery,\n",
      "a dataset of fine-grained academic queries and cor-\n",
      "responding papers drawn from top-tier AI confer-\n",
      "ence publications. To evaluate PaSa in real-world\n",
      "scenarios, we also constructed RealScholarQuery,\n",
      "a dataset of actual academic queries paired with\n",
      "annotated papers. Our experimental results demon-\n",
      "strate that PaSa outperforms all baselines, including\n",
      "Google, Google Scholar, and Google with GPT-4o,\n",
      "ChatGPT, GPT-o1, and PaSa-GPT-4o. In partic-\n",
      "ular, PaSa-7B surpasses Google with GPT-4o by\n",
      "37.78% in recall@20 and 39.90% in recall@50,\n",
      "while also exceeding PaSa-GPT-4o by 30.36% in\n",
      "recall and 4.25% in precision. These findings un-\n",
      "derscore PaSa significantly improves the efficiency\n",
      "and accuracy of academic search.\n",
      "\n",
      "=>\n",
      "9\n",
      "\n",
      "=>\n",
      "Method\n",
      "AutoScholarQuery\n",
      "RealScholarQuery\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "\n",
      "=>\n",
      "w/o [Expand]\n",
      "0.3355\n",
      "0.1445\n",
      "0.2536\n",
      "0.3359\n",
      "0.6738\n",
      "0.2890\n",
      "w/o RL training\n",
      "0.6556\n",
      "0.1476\n",
      "0.4210\n",
      "0.4847\n",
      "0.5155\n",
      "0.4115\n",
      "w/o Selector as RM\n",
      "0.7041\n",
      "0.1535\n",
      "0.4458\n",
      "0.5994\n",
      "0.5489\n",
      "0.5148\n",
      "\n",
      "=>\n",
      "PaSa-7b\n",
      "0.7931\n",
      "0.1448\n",
      "0.4834\n",
      "0.7071\n",
      "0.5146\n",
      "0.6111\n",
      "\n",
      "=>\n",
      "Table 8: Ablation study results on AutoScholarQuery test set and RealScholarQuery.\n",
      "\n",
      "=>\n",
      "α\n",
      "Crawler Recall\n",
      "Crawler Actions\n",
      "\n",
      "=>\n",
      "0.5\n",
      "0.7227\n",
      "175.9\n",
      "1.0\n",
      "0.7708\n",
      "319.8\n",
      "1.5\n",
      "0.7931\n",
      "382.4\n",
      "2.0\n",
      "0.8063\n",
      "785.5\n",
      "\n",
      "=>\n",
      "Table 9: Performance of the Crawler trained on different\n",
      "reward coefficient α on AutoScholarQuery test set.\n",
      "\n",
      "=>\n",
      "References\n",
      "\n",
      "=>\n",
      "Shubham Agarwal, Issam H Laradji, Laurent Char-\n",
      "lin, and Christopher Pal. 2024. Litllm: A toolkit\n",
      "for scientific literature review.\n",
      "arXiv preprint\n",
      "arXiv:2402.01788.\n",
      "\n",
      "=>\n",
      "Marwah Alaofi, Luke Gallagher, Mark Sanderson, Falk\n",
      "Scholer, and Paul Thomas. 2023. Can generative\n",
      "llms create query variants for test collections? an\n",
      "exploratory study. In Proceedings of the 46th in-\n",
      "ternational ACM SIGIR conference on research and\n",
      "development in information retrieval, pages 1869–\n",
      "1873.\n",
      "\n",
      "=>\n",
      "A Anthropic. 2024.\n",
      "The claude 3 model family:\n",
      "Opus, sonnet, haiku; 2024.\n",
      "URL https://www-\n",
      "cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7\n",
      "bbc618857627/Model_Card_Claude_3.pdf.\n",
      "\n",
      "=>\n",
      "Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan,\n",
      "and Sung Ju Hwang. 2024.\n",
      "Researchagent: Iter-\n",
      "ative research idea generation over scientific liter-\n",
      "ature with large language models. arXiv preprint\n",
      "arXiv:2404.07738.\n",
      "\n",
      "=>\n",
      "Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldas-\n",
      "sari, Andrew D White, and Philippe Schwaller. 2023.\n",
      "Chemcrow: Augmenting large-language models with\n",
      "chemistry tools. arXiv preprint arXiv:2304.05376.\n",
      "\n",
      "=>\n",
      "Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang,\n",
      "Jaward Sesay, Börje F Karlsson, Jie Fu, and Yemin\n",
      "Shi. 2023. Autoagents: A framework for automatic\n",
      "agent generation. arXiv preprint arXiv:2309.17288.\n",
      "\n",
      "=>\n",
      "Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam\n",
      "Stevens, Boshi Wang, Huan Sun, and Yu Su. 2024.\n",
      "Mind2web: Towards a generalist agent for the web.\n",
      "Advances in Neural Information Processing Systems,\n",
      "36.\n",
      "\n",
      "=>\n",
      "Peiyuan Feng, Yichen He, Guanhua Huang, Yuan Lin,\n",
      "Hanchong Zhang, Yuchen Zhang, and Hang Li. 2024.\n",
      "Agile: A novel framework of llm agents.\n",
      "arXiv\n",
      "preprint arXiv:2405.14751.\n",
      "\n",
      "=>\n",
      "Team Gemini. 2023.\n",
      "Gemini: a family of highly\n",
      "capable multimodal models.\n",
      "arXiv preprint\n",
      "arXiv:2312.11805.\n",
      "\n",
      "=>\n",
      "Karan Girotra, Lennart Meincke, Christian Terwiesch,\n",
      "and Karl T Ulrich. 2023. Ideas are dimes a dozen:\n",
      "Large language models for idea generation in innova-\n",
      "tion. Available at SSRN 4526071.\n",
      "\n",
      "=>\n",
      "Atharva Gundawar, Mudit Verma, Lin Guan, Karthik\n",
      "Valmeekam, Siddhant Bhambri, and Subbarao Kamb-\n",
      "hampati. 2024. Robust planning with llm-modulo\n",
      "framework: Case study in travel planning. arXiv\n",
      "preprint arXiv:2405.20625.\n",
      "\n",
      "=>\n",
      "Michael Gusenbauer and Neal R Haddaway. 2020.\n",
      "Which academic search systems are suitable for\n",
      "systematic reviews or meta-analyses?\n",
      "evaluating\n",
      "retrieval qualities of google scholar, pubmed, and\n",
      "26 other resources.\n",
      "Research synthesis methods,\n",
      "11(2):181–217.\n",
      "\n",
      "=>\n",
      "Michael Gusenbauer and Neal R Haddaway. 2021.\n",
      "What every researcher should know about searching–\n",
      "clarified concepts, search advice, and an agenda to\n",
      "improve finding in academia. Research synthesis\n",
      "methods, 12(2):136–147.\n",
      "\n",
      "=>\n",
      "Aaron Hurst, Adam Lerer, Adam P Goucher, Adam\n",
      "Perelman, Aditya Ramesh, Aidan Clark, AJ Os-\n",
      "trow, Akila Welihinda, Alan Hayes, Alec Radford,\n",
      "et al. 2024. Gpt-4o system card. arXiv preprint\n",
      "arXiv:2410.21276.\n",
      "\n",
      "=>\n",
      "Karl Kingsley, Gillian M Galbraith, Matthew Herring,\n",
      "Eva Stowers, Tanis Stewart, and Karla V Kingsley.\n",
      "2011. Why not just google it? an assessment of\n",
      "information literacy skills in a biomedical science\n",
      "curriculum. BMC medical education, 11:1–8.\n",
      "\n",
      "=>\n",
      "Minghan Li, Honglei Zhuang, Kai Hui, Zhen Qin,\n",
      "Jimmy Lin, Rolf Jagerman, Xuanhui Wang, and\n",
      "Michael Bendersky. 2023.\n",
      "Generate, filter, and\n",
      "fuse: Query expansion via multi-step keyword gen-\n",
      "eration for zero-shot neural rankers. arXiv preprint\n",
      "arXiv:2311.09175.\n",
      "\n",
      "=>\n",
      "Zhehui Liao, Maria Antoniak, Inyoung Cheong, Evie\n",
      "Yu-Yen Cheng, Ai-Heng Lee, Kyle Lo, Joseph Chee\n",
      "\n",
      "=>\n",
      "10\n",
      "\n",
      "=>\n",
      "Chang, and Amy X Zhang. 2024. Llms as research\n",
      "tools: A large scale survey of researchers’ usage and\n",
      "perceptions. arXiv preprint arXiv:2411.05025.\n",
      "\n",
      "=>\n",
      "Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi\n",
      "Ke, Boyi Liu, and Zhaoran Wang. 2023. Reason for\n",
      "future, act for now: A principled framework for au-\n",
      "tonomous llm agents with provable sample efficiency.\n",
      "arXiv preprint arXiv:2309.17382.\n",
      "\n",
      "=>\n",
      "Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foer-\n",
      "ster, Jeff Clune, and David Ha. 2024. The ai scientist:\n",
      "Towards fully automated open-ended scientific dis-\n",
      "covery. arXiv preprint arXiv:2408.06292.\n",
      "\n",
      "=>\n",
      "Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Bal-\n",
      "dassari, Andrew D White, and Philippe Schwaller.\n",
      "2024. Augmenting large language models with chem-\n",
      "istry tools. Nature Machine Intelligence, pages 1–11.\n",
      "\n",
      "=>\n",
      "Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao,\n",
      "and Nan Duan. 2023. Query rewriting for retrieval-\n",
      "augmented large language models. arXiv preprint\n",
      "arXiv:2305.14283.\n",
      "\n",
      "=>\n",
      "Lisa Messeri and MJ Crockett. 2024. Artificial intel-\n",
      "ligence and illusions of understanding in scientific\n",
      "research. Nature, 627(8002):49–58.\n",
      "\n",
      "=>\n",
      "OpenAI. 2023. Gpt-4 technical report. arXiv preprint\n",
      "arXiv:2303.08774.\n",
      "\n",
      "=>\n",
      "Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Mered-\n",
      "ith Ringel Morris, Percy Liang, and Michael S Bern-\n",
      "stein. 2023. Generative agents: Interactive simulacra\n",
      "of human behavior. In Proceedings of the 36th An-\n",
      "nual ACM Symposium on User Interface Software\n",
      "and Technology, pages 1–22.\n",
      "\n",
      "=>\n",
      "Wenjun Peng, Guiyang Li, Yue Jiang, Zilong Wang, Dan\n",
      "Ou, Xiaoyi Zeng, Derong Xu, Tong Xu, and Enhong\n",
      "Chen. 2024. Large language model based long-tail\n",
      "query rewriting in taobao search.\n",
      "In Companion\n",
      "Proceedings of the ACM on Web Conference 2024,\n",
      "pages 20–28.\n",
      "\n",
      "=>\n",
      "Pranav Putta, Edmund Mills, Naman Garg, Sumeet\n",
      "Motwani, Chelsea Finn, Divyansh Garg, and Rafael\n",
      "Rafailov. 2024. Agent q: Advanced reasoning and\n",
      "learning for autonomous ai agents. arXiv preprint\n",
      "arXiv:2408.07199.\n",
      "\n",
      "=>\n",
      "Chen Qian, Xin Cong, Cheng Yang, Weize Chen,\n",
      "Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong\n",
      "Sun. 2023. Communicative agents for software de-\n",
      "velopment. arXiv preprint arXiv:2307.07924.\n",
      "\n",
      "=>\n",
      "John Schulman, Filip Wolski, Prafulla Dhariwal,\n",
      "Alec Radford, and Oleg Klimov. 2017.\n",
      "Proxi-\n",
      "mal policy optimization algorithms. arXiv preprint\n",
      "arXiv:1707.06347.\n",
      "\n",
      "=>\n",
      "Yijia Shao, Yucheng Jiang, Theodore Kanell, Peter Xu,\n",
      "Omar Khattab, and Monica Lam. 2024. Assisting\n",
      "in writing Wikipedia-like articles from scratch with\n",
      "large language models. In Proceedings of the 2024\n",
      "\n",
      "=>\n",
      "Conference of the North American Chapter of the\n",
      "Association for Computational Linguistics: Human\n",
      "Language Technologies (Volume 1: Long Papers),\n",
      "pages 6252–6278, Mexico City, Mexico. Association\n",
      "for Computational Linguistics.\n",
      "\n",
      "=>\n",
      "Noah Shinn, Federico Cassano, Ashwin Gopinath,\n",
      "Karthik Narasimhan, and Shunyu Yao. 2024. Re-\n",
      "flexion: Language agents with verbal reinforcement\n",
      "learning. Advances in Neural Information Process-\n",
      "ing Systems, 36.\n",
      "\n",
      "=>\n",
      "Jess Stratton. 2024. An introduction to microsoft copi-\n",
      "lot. In Copilot for Microsoft 365: Harness the Power\n",
      "of Generative AI in the Microsoft Apps You Use Every\n",
      "Day, pages 19–35. Springer.\n",
      "\n",
      "=>\n",
      "Richard Van Noorden and Jeffrey M Perkel. 2023. Ai\n",
      "and science: what 1,600 researchers think. Nature,\n",
      "621(7980):672–675.\n",
      "\n",
      "=>\n",
      "Qingyun Wang, Doug Downey, Heng Ji, and Tom Hope.\n",
      "2024a.\n",
      "SciMON: Scientific inspiration machines\n",
      "optimized for novelty. In Proceedings of the 62nd\n",
      "Annual Meeting of the Association for Computational\n",
      "Linguistics (Volume 1: Long Papers), pages 279–299,\n",
      "Bangkok, Thailand. Association for Computational\n",
      "Linguistics.\n",
      "\n",
      "=>\n",
      "Yidong Wang, Qi Guo, Wenjin Yao, Hongbo Zhang,\n",
      "Xin Zhang, Zhen Wu, Meishan Zhang, Xinyu Dai,\n",
      "Min Zhang, Qingsong Wen, et al. 2024b. Autosur-\n",
      "vey: Large language models can automatically write\n",
      "surveys. arXiv preprint arXiv:2406.10252.\n",
      "\n",
      "=>\n",
      "Frank F Xu, Uri Alon, Graham Neubig, and Vincent Jo-\n",
      "sua Hellendoorn. 2022. A systematic evaluation of\n",
      "large language models of code. In Proceedings of\n",
      "the 6th ACM SIGPLAN International Symposium on\n",
      "Machine Programming, pages 1–10.\n",
      "\n",
      "=>\n",
      "An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui,\n",
      "Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu,\n",
      "Fei Huang, Haoran Wei, et al. 2024. Qwen2. 5 tech-\n",
      "nical report. arXiv preprint arXiv:2412.15115.\n",
      "\n",
      "=>\n",
      "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\n",
      "Shafran, Karthik Narasimhan, and Yuan Cao. 2023.\n",
      "React: synergizing reasoning and acting in language\n",
      "models (2022). arXiv preprint arXiv:2210.03629.\n",
      "\n",
      "=>\n",
      "A\n",
      "Implementation Details of the Crawler\n",
      "\n",
      "=>\n",
      "A.1\n",
      "Imitation learning data generation\n",
      "\n",
      "=>\n",
      "We generate training data for imitation learning on\n",
      "a session-by-session basis. There are two types of\n",
      "sessions: search session (starting from state Sq)\n",
      "and expand session (starting from state Sq+p).\n",
      "For search sessions starting from Sq, we sample\n",
      "user queries from the AutoScholarQuery training\n",
      "set and prompt GPT-4o to generate corresponding\n",
      "search queries. The prompt template is shown in\n",
      "Table 10. The session trajectory is constructed\n",
      "\n",
      "=>\n",
      "11\n",
      "\n",
      "=>\n",
      "by adding a [Search] token before each query,\n",
      "concatenating the queries, and appending a [Stop]\n",
      "token at the end, as shown in Table 11. A total of\n",
      "3,011 search session trajectories are generated.\n",
      "For expand sessions starting from Sq+p, we con-\n",
      "tinue by searching for the generated queries using\n",
      "Google. We then sample papers from the search\n",
      "results and obtain the initial state, which includes\n",
      "both the query and a paper. To build the session tra-\n",
      "jectory, we examine each sub-section of the paper.\n",
      "If the sub-section references at least one paper in\n",
      "the AutoScholarQuery training set corresponding\n",
      "to the query, the sub-section is selected. Otherwise,\n",
      "the sub-section is selected with a 10% probabil-\n",
      "ity to enhance trajectory diversity. The selected\n",
      "sections are filled into the template in Table 11,\n",
      "completing the session trajectory. In total, 9,978\n",
      "expand session trajectories are constructed.\n",
      "\n",
      "=>\n",
      "A.2\n",
      "Roll-Out in PPO training\n",
      "\n",
      "=>\n",
      "During PPO training, each device processes 4 user\n",
      "queries in each step, generating a search session\n",
      "for each user query. Then, 6 expansion sessions\n",
      "are created by randomly sampling 6 papers from\n",
      "the search results. This process is repeated with\n",
      "the expand citation results, yielding 6 additional\n",
      "expand sessions. In total, 16 session trajectories\n",
      "are generated per step.\n",
      "\n",
      "=>\n",
      "B\n",
      "Implementation Details of the Selector\n",
      "\n",
      "=>\n",
      "We begin by sampling user queries from the Au-\n",
      "toScholarQuery training set. For each user query\n",
      "and one of its corresponding papers in the Au-\n",
      "toScholarQuery training set, we prompt GPT-4o\n",
      "to generate a decision token and rationale (see Ta-\n",
      "ble 15 for prompt). We reject any data where the\n",
      "decision token is \"False\", as this contradicts the\n",
      "AutoScholarQuery label. The remaining data are\n",
      "retained as positive <user query, paper> pairs.\n",
      "Next, we simulate a partial paper search using\n",
      "PaSa-GPT-4o. In this simulation, each paper has a\n",
      "50% probability of being added to the paper queue.\n",
      "Pairs where the paper is not selected by GPT-4o\n",
      "and is not in the AutoScholarQuery training set are\n",
      "labeled as negative examples.\n",
      "The final training dataset consists of 19,812\n",
      "<user query, paper> pairs, each with a decision\n",
      "token and rationale generated by GPT-4o, drawn\n",
      "from 9,000 instances in the AutoScholarQuery\n",
      "training set.\n",
      "\n",
      "=>\n",
      "C\n",
      "Selector Test Dataset\n",
      "\n",
      "=>\n",
      "We select 200 queries from the AutoScholarQuery\n",
      "development set. For each query, we perform a\n",
      "Google search and randomly choose one paper\n",
      "from the union of the search results and the relevant\n",
      "paper set in AutoScholarQuery. This yields a set of\n",
      "<user query, paper> pairs. Annotators then evaluate\n",
      "whether each paper aligns with the requirements of\n",
      "the user query. The final test dataset consists of 98\n",
      "positive samples and 102 negative samples.\n",
      "\n",
      "=>\n",
      "D\n",
      "Dataset Examples\n",
      "\n",
      "=>\n",
      "Table 12 shows the examples of queries and corre-\n",
      "sponding papers in RealScholarQuery.\n",
      "\n",
      "=>\n",
      "E\n",
      "Prompt Templates\n",
      "\n",
      "=>\n",
      "E.1\n",
      "Prompts for Baselines\n",
      "\n",
      "=>\n",
      "Table 13 exhibits the search query paraphrasing\n",
      "prompt for the baseline model Google with GPT-\n",
      "4o.\n",
      "Table 14 exhibits the prompt for the baseline\n",
      "model ChatGPT (search-enabled GPT-4o).\n",
      "\n",
      "=>\n",
      "E.2\n",
      "Prompt for Paper Selection\n",
      "\n",
      "=>\n",
      "Table 15 shows the prompt for PaSa selector and\n",
      "gpt-4o to judge whether a paper matches the re-\n",
      "quirements of the user’s query.\n",
      "Table 16 presents the prompt template used with\n",
      "GPT-4o to automatically generate AutoScholar-\n",
      "Query. For each paper, we extract the Related Work\n",
      "section, input it into GPT-4o, and use the prompt to\n",
      "extract scholarly queries and their corresponding\n",
      "paper answers from the Related Work section.\n",
      "\n",
      "=>\n",
      "12\n",
      "\n",
      "=>\n",
      "The prompt for search query generation.\n",
      "\n",
      "=>\n",
      "You are an elite researcher in the field of AI, please generate some mutually exclusive queries in a list to search the relevant\n",
      "papers according to the User Query. Searching for a survey paper would be better.\n",
      "User Query: {user_query}\n",
      "The semantics between generated queries are not mutually inclusive. The format of the list is: [“query1”, “query2”, ...]\n",
      "Queries:\n",
      "\n",
      "=>\n",
      "Table 10: The prompt for GPT-4o to generate search queries from the user query.\n",
      "\n",
      "=>\n",
      "Search Session starting from Sq\n",
      "Expand Session starting from Sq+p\n",
      "\n",
      "=>\n",
      "prompt\n",
      "Please, generate some mutually exclusive queries\n",
      "in a list to search the relevant papers according\n",
      "to the User Query. Searching for survey papers\n",
      "would be better.\n",
      "User Query: {user_query}\n",
      "\n",
      "=>\n",
      "You are conducting research on '{user_query}'. You need to predict\n",
      "which sections to look at to get more relevant papers.\n",
      "Title: {title}\n",
      "Abstract: {abstract}\n",
      "Sections: {sections}\n",
      "\n",
      "=>\n",
      "response\n",
      "[Search] {query 1}\n",
      "[Search] {query 2}\n",
      "...\n",
      "[Stop]\n",
      "\n",
      "=>\n",
      "[Expand] {section 1}\n",
      "[Expand] {section 2}\n",
      "...\n",
      "[Stop]\n",
      "\n",
      "=>\n",
      "Table 11: The session trajectory templates of the Crawler.\n",
      "\n",
      "=>\n",
      "13\n",
      "\n",
      "=>\n",
      "Query: Give me papers about how to rank search results by the use of LLM\n",
      "Query Date: 2024-10-01\n",
      "Answer Papers:\n",
      "[0] Instruction Distillation Makes Large Language Models Efficient Zero-shot Rankers\n",
      "[1] Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels\n",
      "[2] Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting\n",
      "[3] A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models\n",
      "[4] RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models\n",
      "[5] PaRaDe: Passage Ranking using Demonstrations with Large Language Models\n",
      "[6] Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents\n",
      "[7] Large Language Models are Zero-Shot Rankers for Recommender Systems\n",
      "[8] TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy\n",
      "[9] ExaRanker: Explanation-Augmented Neural Ranker\n",
      "[10] RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs\n",
      "[11] Make Large Language Model a Better Ranker\n",
      "[12] LLM-RankFusion: Mitigating Intrinsic Inconsistency in LLM-based Ranking\n",
      "[13] Improving Zero-shot LLM Re-Ranker with Risk Minimization\n",
      "[14] Zero-Shot Listwise Document Reranking with a Large Language Model\n",
      "[15] Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing\n",
      "[16] Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models\n",
      "[17] Large Language Models for Relevance Judgment in Product Search\n",
      "[18] PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document\n",
      "Retrieval\n",
      "[19] Passage-specific Prompt Tuning for Passage Reranking in Question Answering with Large Language Models\n",
      "[20] When Search Engine Services meet Large Language Models: Visions and Challenges\n",
      "[21] RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!\n",
      "[22] Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models\n",
      "[23] MuGI: Enhancing Information Retrieval through Multi-Text Generation Integration with Large Language Models\n",
      "[24] Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker\n",
      "[25] REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering\n",
      "[26] Agent4Ranking: Semantic Robust Ranking via Personalized Query Rewriting Using Multi-agent LLM\n",
      "[27] FIRST: Faster Improved Listwise Reranking with Single Token Decoding\n",
      "[28] Leveraging LLMs for Unsupervised Dense Retriever Ranking\n",
      "[29] Unsupervised Contrast-Consistent Ranking with Language Models\n",
      "[30] Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models\n",
      "[31] Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models\n",
      "[32] Fine-Tuning LLaMA for Multi-Stage Text Retrieval\n",
      "[33] Zero-shot Audio Topic Reranking using Large Language Models\n",
      "[34] Uncovering ChatGPT’s Capabilities in Recommender Systems\n",
      "[35] Cognitive Personalized Search Integrating Large Language Models with an Efficient Memory Mechanism\n",
      "[36] Towards More Relevant Product Search Ranking Via Large Language Models: An Empirical Study\n",
      "[37] Pretrained Language Model based Web Search Ranking: From Relevance to Satisfaction\n",
      "[38] Open-source large language models are strong zero-shot query likelihood models for document ranking\n",
      "\n",
      "=>\n",
      "Table 12: Examples of queries and corresponding papers in RealScholarQuery.\n",
      "\n",
      "=>\n",
      "The prompt for search query paraphrase.\n",
      "\n",
      "=>\n",
      "Generate a search query suitable for Google based on the given academic paper-related query. Here’s the structure and\n",
      "requirements for generating the search query:\n",
      "Understand the Query: Read and understand the given specific academic query.\n",
      "Identify Key Elements: Extract the main research field and the specific approaches or topics mentioned in the query.\n",
      "Formulate the Search Query: Combine these elements into a concise query that includes terms indicating academic sources.\n",
      "Do not add any site limitations to your query.\n",
      "[User’s Query]: {user_query}\n",
      "[Generated Search Query]:\n",
      "\n",
      "=>\n",
      "Table 13: The prompt for search query paraphrase.\n",
      "\n",
      "=>\n",
      "14\n",
      "\n",
      "=>\n",
      "The prompt for ChatGPT (search-enabled GPT-4o).\n",
      "\n",
      "=>\n",
      "[User’s Query]\n",
      "You should return the Arxiv papers. You should provide more than 10 papers you searched in JSON format:\n",
      "{\"paper_1\": {\"title\": , ’authors’: , ’link’: }, \"paper_2\": {\"title\": , ’authors’: , ’link’: }}\n",
      "\n",
      "=>\n",
      "Table 14: The prompt for Chatgpt (search-enabled GPT-4o).\n",
      "\n",
      "=>\n",
      "The prompt for paper selection.\n",
      "\n",
      "=>\n",
      "You are an elite researcher in the field of AI, conducting research on {user_query}. Evaluate whether the following paper\n",
      "fully satisfies the detailed requirements of the user query and provide your reasoning. Ensure that your decision and reasoning\n",
      "are consistent.\n",
      "Searched Paper:\n",
      "Title: {title}\n",
      "Abstract: {abstract}\n",
      "User Query: {user_query}\n",
      "Output format: Decision: True/False\n",
      "Reason:...\n",
      "Decision:\n",
      "\n",
      "=>\n",
      "Table 15: The prompt used with pasa selector or GPT-4o to judge the selection of the paper.\n",
      "\n",
      "=>\n",
      "The prompt for AutoScholarQuery generation.\n",
      "\n",
      "=>\n",
      "You are provided a ‘Related Work’ section of a research paper. The researcher reviewed the relevant work, conducted a\n",
      "literature survey, and cited corresponding references in this text (enclosed by ‘\\cite’ tags with IDs). Can you guess what\n",
      "research questions the researcher might have posed when preparing this text? The answers to these questions should be the\n",
      "references cited in this passage. Please list questions and provide the corresponding answers.\n",
      "[Requirements:]\n",
      "1. Craft questions similar to those a researcher would pose when reviewing related works, such as “Which paper studied ...?”,\n",
      "“Any works about...?”, “Could you provide me some works...?”\n",
      "2. Construct the question-answer pairs based on [Section from A Research Paper]. The answer should be the cited papers in\n",
      "[Section from A Research Paper].\n",
      "3. Do not ask questions including \"or\" or \"and\" that may involve more than one condition.\n",
      "4. Clarity: Formulate questions clearly and unambiguously to prevent confusion.\n",
      "5. Contextual Definitions: Include explanations or definitions for specialized terms and concepts used in the questions.\n",
      "6. Format the output as a JSON array containing five objects corresponding to the three question-answer pairs.\n",
      "Here are some examples:\n",
      "[Begin of examples]\n",
      "{Section from A Research Paper-1}\n",
      "{OUTPUT-1}\n",
      "{Section from A Research Paper-2}\n",
      "{OUTPUT-2}\n",
      "{Section from A Research Paper-3}\n",
      "{OUTPUT-3}\n",
      "[End of examples]\n",
      "{Section from A Research Paper}\n",
      "[OUTPUT]:\n",
      "\n",
      "=>\n",
      "Table 16: The prompt used with GPT-4o to automatically generate AutoScholarQuery.\n",
      "\n",
      "=>\n",
      "15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def extract_text_from_pdf(url):\n",
    "    response = requests.get(url)\n",
    "    pdf_content = BytesIO(response.content)\n",
    "    document = fitz.Document(stream=pdf_content, filetype=\"pdf\")\n",
    "\n",
    "    # Extract text from each page\n",
    "    doc_blocks = []\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        page_blocks = page.get_text(\"blocks\")\n",
    "        for block in page_blocks:\n",
    "            doc_blocks.append(block[4])\n",
    "\n",
    "    return doc_blocks\n",
    "\n",
    "# Example usage\n",
    "# pdf_path = \"../data/RAG.pdf\"\n",
    "# pdf_path = \"../data/LayoutLM.pdf\"\n",
    "url = \"https://arxiv.org/pdf/2501.10120\"\n",
    "doc_blocks = extract_text_from_pdf(url)\n",
    "\n",
    "for block in doc_blocks:\n",
    "    print(\"=>\")\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 190\n",
      "=>\n",
      " We introduce PaSa, an advanced Paper Search\n",
      "agent powered by large language models. PaSa\n",
      "can autonomously make a series of decisions,\n",
      "including invoking search tools, reading pa-\n",
      "pers, and selecting relevant references, to ul-\n",
      "timately obtain comprehensive and accurate\n",
      "results for complex scholarly queries. We op-\n",
      "timize PaSa using reinforcement learning with\n",
      "a synthetic dataset, AutoScholarQuery, which\n",
      "includes 35k fine-grained academic queries and\n",
      "corresponding papers sourced from top-tier AI\n",
      "conference publications. Additionally, we de-\n",
      "velop RealScholarQuery, a benchmark collect-\n",
      "ing real-world academic queries to assess PaSa\n",
      "performance in more realistic scenarios. De-\n",
      "spite being trained on synthetic data, PaSa sig-\n",
      "nificantly outperforms existing baselines on\n",
      "RealScholarQuery, including Google, Google\n",
      "Scholar, Google with GPT-4 for paraphrased\n",
      "queries, chatGPT (search-enabled GPT-4o),\n",
      "GPT-o1, and PaSa-GPT-4o (PaSa implemented\n",
      "by prompting GPT-4o). Notably, PaSa-7B sur-\n",
      "passes the best Google-based baseline, Google\n",
      "with GPT-4o, by 37.78% in recall@20 and\n",
      "39.90% in recall@50. It also exceeds PaSa-\n",
      "GPT-4o by 30.36% in recall and 4.25% in pre-\n",
      "cision. Model, datasets, and code are available\n",
      "at https://github.com/bytedance/pasa.\n",
      "\n",
      "=>\n",
      " ∗Equal contribution.\n",
      "†Corresponding author.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 1\n",
      "Introduction\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Academic paper search lies at the core of research\n",
      "yet represents a particularly challenging informa-\n",
      "tion retrieval task. It requires long-tail special-\n",
      "ized knowledge, comprehensive survey-level cover-\n",
      "age, and the ability to address fine-grained queries.\n",
      "For instance, consider the query: \"Which stud-\n",
      "ies have focused on non-stationary reinforcement\n",
      "learning using value-based methods, specifically\n",
      "UCB-based algorithms?\" While widely used aca-\n",
      "demic search systems like Google Scholar are effec-\n",
      "tive for general queries, they often fall short when\n",
      "addressing these complex queries (Gusenbauer and\n",
      "Haddaway, 2020). Consequently, researchers fre-\n",
      "quently spend substantial time conducting litera-\n",
      "ture surveys (Kingsley et al., 2011; Gusenbauer\n",
      "and Haddaway, 2021).\n",
      "\n",
      "=>\n",
      " The advancements in large language models\n",
      "(LLMs) (OpenAI, 2023; Anthropic, 2024; Gemini,\n",
      "2023; Yang et al., 2024) have inspired numerous\n",
      "studies leveraging LLMs to enhance information\n",
      "retrieval, particularly by refining or reformulating\n",
      "search queries to improve retrieval quality (Alaofi\n",
      "et al., 2023; Li et al., 2023; Ma et al., 2023; Peng\n",
      "et al., 2024). In academic search, however, the\n",
      "process goes beyond simple retrieval. Human re-\n",
      "searchers not only use search tools, but also engage\n",
      "in deeper activities, such as reading relevant papers\n",
      "and checking citations, to perform comprehensive\n",
      "and accurate literature surveys.\n",
      "\n",
      "=>\n",
      " 1\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " arXiv:2501.10120v1  [cs.IR]  17 Jan 2025\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Paper Queue\n",
      "Crawler\n",
      "User Query\n",
      "Selector\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " User Query\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Select / Drop\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Search]\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Expand]\n",
      "[Stop]\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Figure 1: Architecture of PaSa. The system consists of two LLM agents, Crawler and Selector. The Crawler\n",
      "processes the user query and can access papers from the paper queue. It can autonomously invoke the search tool,\n",
      "expand citations, or stop processing of the current paper. All papers collected by the Crawler are appended to the\n",
      "paper queue. The Selector reads each paper in the paper queue to determine whether it meets the criteria specified in\n",
      "the user query.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " In this paper, we introduce PaSa, a novel paper\n",
      "search agent designed to mimic human behavior\n",
      "for comprehensive and accurate academic paper\n",
      "searches. As illustrated in Figure 1, PaSa con-\n",
      "sists of two LLM agents: the Crawler and the Se-\n",
      "lector. For a given user query, the Crawler can\n",
      "autonomously collect relevant papers by utilizing\n",
      "search tools or extracting citations from the current\n",
      "paper, which are then added to a growing paper\n",
      "queue. The Crawler iteratively processes each pa-\n",
      "per in the paper queue, navigating citation networks\n",
      "to discover increasingly relevant papers. The Selec-\n",
      "tor carefully reads each paper in the paper queue to\n",
      "determine whether it meets the requirements of the\n",
      "user query. We optimize PaSa within the AGILE, a\n",
      "reinforcement learning (RL) framework for LLM\n",
      "agents (Feng et al., 2024).\n",
      "Effective training requires high-quality academic\n",
      "search data. Fortunately, human scientists have al-\n",
      "ready created a vast amount of high-quality aca-\n",
      "demic papers, which contain extensive surveys on\n",
      "a wide range of research topics. We build a syn-\n",
      "thetic but high-quality academic search dataset,\n",
      "AutoScholarQuery, which collects fine-grained\n",
      "scholar queries and their corresponding relevant\n",
      "papers from the related work sections of papers\n",
      "published at ICLR 2023 1, ICML 2023 2, NeurIPS\n",
      "2023 3, ACL 2024 4, and CVPR 2024 5.\n",
      "Au-\n",
      "toScholarQuery includes 33,511 / 1,000 / 1,000\n",
      "query-paper pairs in the training / development /\n",
      "test split.\n",
      "\n",
      "=>\n",
      " 1https://iclr.cc/Conferences/2023\n",
      "2https://icml.cc/Conferences/2023\n",
      "3https://neurips.cc/Conferences/2023\n",
      "4https://2024.aclweb.org/\n",
      "5https://cvpr.thecvf.com/Conferences/2024\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Although AutoScholarQuery only provides\n",
      "query and paper answers, without demonstrating\n",
      "the path by which scientists collect the papers, we\n",
      "can utilize them to perform RL training to improve\n",
      "PaSa. In addition, we design a new session-level\n",
      "PPO (Proximal Policy Optimization (Schulman\n",
      "et al., 2017)) training method to address the unique\n",
      "challenges of the paper search task: 1) sparse re-\n",
      "ward: The papers in AutoScholarQuery are col-\n",
      "lected via citations, making it a smaller subset of\n",
      "the actual qualified paper set. 2) long trajectories:\n",
      "The complete trajectory of the Crawler may involve\n",
      "hundreds of papers, which is too long to directly\n",
      "input into the LLM context.\n",
      "\n",
      "=>\n",
      " To evaluate PaSa, besides the test set of Au-\n",
      "toScholarQuery, we also develop a benchmark, Re-\n",
      "alScholarQuery. It contains 50 real-world academic\n",
      "queries with annotated relevant papers, to assess\n",
      "PaSa in real-world scenarios. We compare PaSa\n",
      "with several baselines including Google, Google\n",
      "Scholar, Google paired with GPT-4o for para-\n",
      "phrased queries, chatGPT (search-enabled GPT-\n",
      "4o), GPT-o1 and PaSa-GPT-4o (PaSa agent real-\n",
      "ized by prompting GPT-4o). Our experiments show\n",
      "that PaSa-7b significantly outperforms all baselines.\n",
      "Specifically, for AutoScholarQuery test set, PaSa-\n",
      "7b achieves a 34.05% improvement in Recall@20\n",
      "and a 39.36% improvement in Recall@50 com-\n",
      "pared to Google with GPT-4o, the strongest Google-\n",
      "based baseline. PaSa-7b surpasses PaSa-GPT-4o\n",
      "by 11.12% in recall, with similar precision. For\n",
      "RealScholarQuery, PaSa-7b outperforms Google\n",
      "with GPT-4o by 37.78% in Recall@20 and 39.90%\n",
      "in Recall@50. PaSa-7b surpasses PaSa-GPT-4o by\n",
      "30.36% in recall and 4.25% in precision.\n",
      "\n",
      "=>\n",
      " 2\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " The main contributions of this paper are summa-\n",
      "rized as follows:\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " • We introduce PaSa, a comprehensive and accu-\n",
      "rate paper search agent that can autonomously\n",
      "use online search tools, read entire papers, and\n",
      "navigate citation networks.\n",
      "\n",
      "=>\n",
      " • We develop two high-quality datasets for com-\n",
      "plex academic search, AutoScholarQuery and\n",
      "RealScholarQuery.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " • Although PaSa is trained solely on synthetic\n",
      "data, it achieves remarkable real-world perfor-\n",
      "mance. Experiments demonstrate that PaSa,\n",
      "built on 7B LLM, significantly outperforms\n",
      "all baselines, including GPT-4 agent, Google-\n",
      "based search, and chatGPT.\n",
      "\n",
      "=>\n",
      " 2\n",
      "Related Work\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " LLMs in Scientific Discovery\n",
      "LLMs have been\n",
      "applied across various stages of scientific discov-\n",
      "ery (Van Noorden and Perkel, 2023; Lu et al., 2024;\n",
      "Messeri and Crockett, 2024; Liao et al., 2024), such\n",
      "as brainstorming ideas (Girotra et al., 2023; Wang\n",
      "et al., 2024a; Baek et al., 2024), designing exper-\n",
      "iments (M. Bran et al., 2024), writing code (Xu\n",
      "et al., 2022), and generating research papers (Shao\n",
      "et al., 2024; Agarwal et al., 2024; Wang et al.,\n",
      "2024b). One of the most fundamental yet criti-\n",
      "cal stages in research is conducting academic sur-\n",
      "veys. Despite its importance, current tools like\n",
      "Google Scholar are often insufficient, leading re-\n",
      "searchers to spend considerable time on literature\n",
      "review tasks (Kingsley et al., 2011; Gusenbauer\n",
      "and Haddaway, 2021, 2020). This challenge moti-\n",
      "vates us to develop PaSa, an LLM agent designed\n",
      "to autonomously and comprehensively assist re-\n",
      "searchers in collecting relevant research papers for\n",
      "complex scholarly queries.\n",
      "\n",
      "=>\n",
      " LLM Agents\n",
      "LLM Agents combine LLMs with\n",
      "memory, tool use, and planning, enabling them to\n",
      "perform more complex tasks such as personal copi-\n",
      "lots (Stratton, 2024), travel planning (Gundawar\n",
      "et al., 2024), web operations (Deng et al., 2024),\n",
      "software development (Qian et al., 2023), and sci-\n",
      "entific experimentation (Bran et al., 2023). In ad-\n",
      "dition to realizing LLM Agents through prompt\n",
      "engineering (Park et al., 2023; Yao et al., 2023;\n",
      "Shinn et al., 2024; Chen et al., 2023), recent re-\n",
      "search has focused on optimizing and training these\n",
      "agents (Feng et al., 2024; Putta et al., 2024; Liu\n",
      "\n",
      "=>\n",
      " et al., 2023). Among these efforts, AGILE (Feng\n",
      "et al., 2024), a reinforcement learning framework\n",
      "for LLM agents, allows the joint optimization of all\n",
      "agent skills in an end-to-end manner. In our work,\n",
      "we adopt the AGILE framework to implement PaSa.\n",
      "Specifically, we design a novel session-level PPO\n",
      "algorithm to address the unique challenges of the\n",
      "paper search task, including sparse rewards and\n",
      "long trajectories.\n",
      "\n",
      "=>\n",
      " 3\n",
      "Datasets\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 3.1\n",
      "AutoScholarQuery\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " AutoScholarQuery is a synthetic but high-quality\n",
      "dataset of academic queries and related papers,\n",
      "specifically curated for the AI field.\n",
      "To construct AutoScholarQuery, we began by\n",
      "collecting all papers published at ICLR 2023,\n",
      "ICML 2023, NeurIPS 2023, ACL 2024, and CVPR\n",
      "2024. For the Related Work section of each paper,\n",
      "we prompted GPT-4o (Hurst et al., 2024) to gener-\n",
      "ate scholarly queries, where the answers to these\n",
      "queries correspond to the references cited in the\n",
      "Related Work section. The prompt used is shown\n",
      "in Appendix E.1. For each query, we retained only\n",
      "the papers that could be retrieved on arXiv6, using\n",
      "their arxiv_id as the unique article identifier in the\n",
      "dataset. We adopt the publication date of the source\n",
      "paper as the query date. During both training and\n",
      "testing, we only considered papers published prior\n",
      "to the query date.\n",
      "The final AutoScholarQuery dataset comprises\n",
      "33,551, 1,000, and 1,000 instances in the train-\n",
      "ing, development, and testing splits, respectively.\n",
      "Each instance consists of a query, the associated\n",
      "paper set, and the query date, with queries in each\n",
      "split derived from distinct source papers. Table 1\n",
      "provides illustrative examples from AutoScholar-\n",
      "Query, while additional dataset statistics are sum-\n",
      "marized in Table 2.\n",
      "To evaluate the quality of AutoScholarQuery,\n",
      "we sampled 100 query-paper pairs and assessed\n",
      "the rationality and relevance of each query and\n",
      "the corresponding paper. A qualified query should\n",
      "be meaningful and unambiguous. A qualified pa-\n",
      "per should match the requirements of the scholarly\n",
      "query. The author manually reviewed each pair,\n",
      "determining that 94.0% of the queries were qual-\n",
      "ified. Among these qualified queries, 93.7% had\n",
      "corresponding papers that were deemed relevant\n",
      "and appropriate.\n",
      "\n",
      "=>\n",
      " 6https://arxiv.org/\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 3\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Query: Could you provide me some studies that proposed hierarchical neural models to capture spatiotemporal features in sign\n",
      "videos?\n",
      "Query Date: 2023-05-02\n",
      "Answer Papers:\n",
      "[1] TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation\n",
      "[2] Sign Language Translation with Hierarchical Spatio-Temporal Graph Neural Network\n",
      "Source: SLTUnet: A Simple Unified Model for Sign Language Translation, ICLR 2023\n",
      "Query: Which studies have focused on nonstationary RL using value-based methods, specifically Upper Confidence Bound (UCB)\n",
      "based algorithms?\n",
      "Query Date: 2023-08-10\n",
      "Answer Papers:\n",
      "[1] Reinforcement Learning for Non-Stationary Markov Decision Processes: The Blessing of (More) Optimism\n",
      "[2] Efficient Learning in Non-Stationary Linear Markov Decision Processes\n",
      "[3] Nonstationary Reinforcement Learning with Linear Function Approximation\n",
      "Source: Provably Efficient Algorithm for Nonstationary Low-Rank MDPs, NeurIPS 2023\n",
      "Query: Which studies have been conducted in long-form text generation, specifically in story generation?\n",
      "Query Date: 2024-01-26\n",
      "Answer Papers:\n",
      "[1] Strategies for Structuring Story Generation\n",
      "[2] MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models\n",
      "Source: ProxyQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models, ACL 2024\n",
      "\n",
      "=>\n",
      " Table 1: Examples of queries and corresponding papers in AutoScholarQuery.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Conference\n",
      "|P|\n",
      "|Q|\n",
      "Ans(/Q)\n",
      "Ans-50\n",
      "Ans-90\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " ICLR 2023\n",
      "888\n",
      "5204\n",
      "2.46\n",
      "2.0\n",
      "5.0\n",
      "ICML 2023\n",
      "981\n",
      "5743\n",
      "2.37\n",
      "2.0\n",
      "5.0\n",
      "NeurIPS 2023\n",
      "1948\n",
      "11761\n",
      "2.59\n",
      "2.0\n",
      "5.0\n",
      "CVPR 2024\n",
      "1336\n",
      "9528\n",
      "2.94\n",
      "2.0\n",
      "6.0\n",
      "ACL 2024\n",
      "485\n",
      "3315\n",
      "2.16\n",
      "2.0\n",
      "4.0\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Table 2: Statistics of AutoScholarQuery. |P| and |Q|\n",
      "represent the total number of papers and queries col-\n",
      "lected for each conference. Ans(/Q) denotes the aver-\n",
      "age number of answer papers per query. Ans-50 and\n",
      "Ans-90 refers to the 50th and 90th percentiles of answer\n",
      "paper counts per query.\n",
      "\n",
      "=>\n",
      " 3.2\n",
      "RealScholarQuery\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " To evaluate PaSa in more realistic scenarios, we\n",
      "constructed RealScholarQuery, a test dataset con-\n",
      "sisting of 50 real-world research queries. After\n",
      "launching the demo of PaSa, we invited several AI\n",
      "researchers to use the system. From the queries\n",
      "they provided, we randomly sampled a subset of\n",
      "queries and manually filtered out overly broad top-\n",
      "ics (e.g., \"multi-modal large language models,\"\n",
      "\"video generation\"). Ultimately, we collected 50\n",
      "fine-grained and realistic queries.\n",
      "For each query, we first manually gathered rele-\n",
      "vant papers. Subsequently, we used multiple meth-\n",
      "ods to retrieve additional papers, including PaSa,\n",
      "Google, Google Scholar, ChatGPT (search-enabled\n",
      "GPT-4o), and Google paired with GPT-4o for para-\n",
      "phrased queries. The results from these methods\n",
      "were aggregated into a pool of candidate papers.\n",
      "Finally, professional annotators reviewed all can-\n",
      "didate papers for each query, selecting those that\n",
      "\n",
      "=>\n",
      " met the specific requirements of the query to create\n",
      "the final set of relevant papers. The query date of\n",
      "all instances in RealScholarQuery is 2024-10-01.\n",
      "Table 12 in Appendix D provides examples from\n",
      "RealScholarQuery.\n",
      "\n",
      "=>\n",
      " The annotators included professors from the De-\n",
      "partment of Computer Science at a top-tier univer-\n",
      "sity in China. On average, each query required the\n",
      "annotators to review 76 candidate papers. Given\n",
      "the high cost of the annotations, we completed this\n",
      "process for only 50 instances.\n",
      "\n",
      "=>\n",
      " 4\n",
      "Methodology\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 4.1\n",
      "Overview\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " As illustrated in Figure 1, the PaSa system consists\n",
      "of two LLM agents: Crawler and Selector. The\n",
      "crawler reads the user’s query, generates multiple\n",
      "search queries, and retrieves relevant papers. The\n",
      "retrieved papers are added to a paper queue. The\n",
      "Crawler further processes each paper in the paper\n",
      "queue to identify key citations worth exploring fur-\n",
      "ther, appending any newly relevant papers to the\n",
      "paper list. The selector conducts a thorough review\n",
      "of each paper in the paper list to assess whether it\n",
      "fulfills the user’s query requirements.\n",
      "\n",
      "=>\n",
      " In summary, the Crawler is designed to maxi-\n",
      "mize the recall of relevant papers, whereas the Se-\n",
      "lector emphasizes precision in identifying papers\n",
      "that meet the user’s needs.\n",
      "\n",
      "=>\n",
      " 4\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Is there any works that analyze the scaling law of the multi-module models, such as video-text, image-text models.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Search]Analysis of scaling \n",
      "law in video-text models\n",
      "[Search]Scaling laws in \n",
      "multi-modal AI models\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Search]Image-text \n",
      "model scaling laws research\n",
      "[Search]Survey papers on \n",
      "scaling law of multi-module models\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Stop]\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Neural Scaling \n",
      "Laws for Embodied \n",
      "AI\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "Scaling Law \n",
      "Hypothesis for \n",
      "Multimodal Model\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Scaling Laws for \n",
      "Generative Mixed-Modal \n",
      "Language Models\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Expand]1 Introduction\n",
      "[Expand]…\n",
      "[Expand]3 Empirical approach \n",
      "Research paper meta analysis\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Expand]4 Results 4.1 Scaling Laws \n",
      "for Robot Foundation Models\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Stop]\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Foundation models in robotics: \n",
      "Applications, challenges, and \n",
      "the future\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Expand]II Foundation \n",
      "Models Background       \n",
      "II-D Multimodal Vision-\n",
      "Language Models (VLMs)\n",
      "Scaling language-image \n",
      "pre-training via masking\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Expand]IV Perception \n",
      "IV-A Open-Vocabulary \n",
      "Object Detection and 3D \n",
      "Classification\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Stop]\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Simple open-\n",
      "vocabulary \n",
      "object detection \n",
      "with vision \n",
      "transformers\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Foundation \n",
      "models in \n",
      "robotics: \n",
      "Applications, \n",
      "challenges, and \n",
      "the future\n",
      "[Stop]\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Crawler\n",
      "Selector Select\n",
      "Selector Drop\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " …\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Figure 2: An example of the PaSa workflow. The Crawler runs multiple [Search] using diverse and complementary\n",
      "queries. In addition, the Crawler can evaluate the long-term value of its actions. Notably, it discovers many relevant\n",
      "papers as it explores deeper on the citation network, even when intermediate papers along the path do not align with\n",
      "the user query.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Name\n",
      "Implementation\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Generate a search query and invoke\n",
      "[Search]\n",
      "the search tool. Append all resulting\n",
      "papers to the paper queue.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Generate a subsection name, then\n",
      "[Expand]\n",
      "add all referenced papers in the sub-\n",
      "section to the paper queue.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " [Stop]\n",
      "Reset the context to the user query and\n",
      "the next paper in the paper queue.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Table 3: Functions of the Crawler.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 4.2\n",
      "Crawler\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " In RL terminology, the Crawler performs a token-\n",
      "level Markov Decision Process (MDP). The ac-\n",
      "tion space A corresponds to the LLM’s vocabulary,\n",
      "where each token represents an action. The LLM\n",
      "functions as the policy model. The agent’s state is\n",
      "defined by the current LLM context and the paper\n",
      "queue. The Crawler operates with three registered\n",
      "functions, as outlined in Table 3. When an ac-\n",
      "tion matches a function name, the corresponding\n",
      "function is executed, further modifying the agent’s\n",
      "state.\n",
      "For example, as Figure 2 shows, the agent begins\n",
      "by receiving a user query, incorporating it into its\n",
      "context, and initiating actions. If the token gener-\n",
      "ated is [Search], the LLM continues to generate a\n",
      "search query, and the agent invokes a search tool to\n",
      "retrieve papers, which are then added to the paper\n",
      "list. If the token is [Expand], the LLM continues\n",
      "to extract a subsection name from the current pa-\n",
      "\n",
      "=>\n",
      " per in its context. The agent subsequently uses a\n",
      "parsing tool to extract all referenced papers within\n",
      "that subsection, adding them to the paper list. If\n",
      "the token is [Stop], the agent resets its context to\n",
      "the user query and information of the next paper\n",
      "in the paper queue. This information includes the\n",
      "title, abstract, and an outline of all sections and\n",
      "subsections.\n",
      "The training process for the Crawler comprises\n",
      "two stages. In the first stage, we generate trajec-\n",
      "tories for a small subset of the training data and\n",
      "then perform imitation learning (see Appendix A.1\n",
      "for details). In the second stage, reinforcement\n",
      "learning is applied. The details of the RL training\n",
      "implementation are described below.\n",
      "\n",
      "=>\n",
      " Reward Design\n",
      "We conduct RL training on the\n",
      "AutoScholarQuery training set, where each in-\n",
      "stance consists of a query q and a corresponding\n",
      "paper set P. Starting with a query q, the Crawler\n",
      "generates a trajectory τ = (s1, a1, · · · , sT , aT ). At\n",
      "each time step t, we denote the current paper queue\n",
      "as Qt. Upon taking action at, the Crawler appends\n",
      "a set of new papers (p1, p2, · · · , pnt) to the paper\n",
      "queue. If at = [Stop], the set is empty.\n",
      "The reward of executing action at in state st is\n",
      "defined as\n",
      "\n",
      "=>\n",
      " r(st, at) = α ×\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " nt\n",
      "X\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " i=1\n",
      "I(q, pi, t) −c(at),\n",
      "(1)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " where I(q, pi, t) = 1 if pi matches the query q and\n",
      "is not already in Qt, and I(q, pi, t) = 0 otherwise.\n",
      "\n",
      "=>\n",
      " 5\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Here, α is a reward coefficient, and c(at) is the cost\n",
      "of action at.\n",
      "The indicator function I(q, pi, t) can be deter-\n",
      "mined by checking if pi belongs to P −Qt. How-\n",
      "ever, it is important to note that the AutoScholar-\n",
      "Query may only include a subset of the ground-\n",
      "truth papers, as citations often emphasize a limited\n",
      "number of key references. If the Crawler receives\n",
      "rewards solely based on matching papers in Au-\n",
      "toScholarQuery, this could lead to sparse rewards\n",
      "during training. To mitigate this, we use the Selec-\n",
      "tor as an auxiliary reward model for the Crawler.\n",
      "The revised definition of I(q, pi, t) is:\n",
      "\n",
      "=>\n",
      " I(q, pi, t) =\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " \n",
      "\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 1,\n",
      "if (Selector(q, pi) = 1 or pi ∈P)\n",
      "and pi /∈Qt,\n",
      "0,\n",
      "otherwise.\n",
      "(2)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Here Selector(q, pi) = 1 if paper pi is identified\n",
      "as correct to meet the query q by the Selector, and\n",
      "Selector(q, pi) = 0 otherwise.\n",
      "\n",
      "=>\n",
      " RL Training\n",
      "A key challenge in training the\n",
      "Crawler with RL is the significant time required\n",
      "to sample a complete trajectory for a given query.\n",
      "This is due to each [Search] or [Expand] action\n",
      "adding multiple papers to the paper list, resulting\n",
      "in hundreds or even thousands of papers in the final\n",
      "paper queue.\n",
      "To address this issue, we define a session as a\n",
      "sub-trajectory that begins with a session’s initial\n",
      "state and ends with the [Stop] action. We iden-\n",
      "tify two types of session initial states: Sq, which\n",
      "includes only a query, and Sq+p, which consists of\n",
      "both a query and a paper.\n",
      "Formally,\n",
      "we\n",
      "model\n",
      "the\n",
      "Crawler\n",
      "as\n",
      "a\n",
      "policy πθ(at|st).\n",
      "We partition the entire\n",
      "trajectory\n",
      "τ\n",
      "into\n",
      "a\n",
      "sequence\n",
      "of\n",
      "sessions:\n",
      "(τt1:t2−1, τt2:t3−1, · · · ).\n",
      "Each\n",
      "session\n",
      "is\n",
      "τti:ti+1−1\n",
      "=\n",
      "(sti, ati, · · · , sti+1−1, ati+1−1),\n",
      "where the initial state sti is either belonging to\n",
      "type Sq or Sq+p, and the final action ati+1−1 is\n",
      "[STOP].\n",
      "Sampling such a sub-trajectory from these ses-\n",
      "sion initial states is computationally efficient. Dur-\n",
      "ing the PPO training, at time step t ∈[ti, ti+1),\n",
      "we estimate the return in the session using Monte\n",
      "Carlo sampling:\n",
      "\n",
      "=>\n",
      " ˆRt\n",
      "=\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " ti+1−1−t\n",
      "X\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " k=0\n",
      "γk\n",
      "0\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " \u0014\n",
      "r(st+k, at+k)\n",
      "(3)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " +γ1\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " nt+k\n",
      "X\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " j=1\n",
      "ˆVϕ(Sq+pj) −β · log πθ(at|st)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " πsft(at|st)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " \u0015\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Here, γ0 is the in-session discount factor, and\n",
      "γ1 is the across-session discount factor.\n",
      "ˆVϕ(·)\n",
      "is the value function model to approximate the\n",
      "state value. After executing at+k, the paper queue\n",
      "is updated to include the newly found papers\n",
      "(p1, p2, · · · , pnt+k). Since the Crawler will subse-\n",
      "quently initiate new sessions to process these addi-\n",
      "tional papers, their associated reward-to-go should\n",
      "be incorporated into the return estimate. In addi-\n",
      "tion, we include a per-token KL penalty term from\n",
      "the learned policy πθ to the initial policy πsft ob-\n",
      "tained through imitation learning at each token to\n",
      "mitigate over-optimization. This term is scaled by\n",
      "the coefficient β.\n",
      "Then the advantage function can be approxi-\n",
      "mated by\n",
      "\n",
      "=>\n",
      " ˆA(st, at)\n",
      "=\n",
      "ˆRt −ˆVϕ(st).\n",
      "(4)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Finally, the policy and value objectives can be\n",
      "given by\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Lpolicy(θ) =Eτ′∼πold\n",
      "θ\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " \"\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " min\n",
      "\u0012 πθ(at|st)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " πold\n",
      "θ (at|st)\n",
      "ˆA(st, at),\n",
      "(5)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " clip\n",
      "\u0010 πθ(at|st)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " πold\n",
      "θ (at|st), 1 −ϵ, 1 + ϵ\n",
      "\u0011\n",
      "ˆA(st, at)\n",
      "\u0013#\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " and\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Lvalue(ϕ) =\n",
      "Eτ′∼πold\n",
      "θ\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " \"\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " max\n",
      "\u0012\u0010\n",
      "ˆRt −ˆVϕ(st)\n",
      "\u00112\n",
      ",\n",
      "(6)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " \u0010\n",
      "ˆRt −ˆV clip\n",
      "ϕ\n",
      "(st)\n",
      "\u00112\u0013#\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " ,\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " respectively, where\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " ˆV clip\n",
      "ϕ\n",
      "(st) =\n",
      "clip\n",
      "\u0010\n",
      "ˆVϕ(st), V old\n",
      "ϕ (st) −ϵ, V old\n",
      "ϕ (st) + ϵ\n",
      "\u0011\n",
      ". (7)\n",
      "\n",
      "=>\n",
      " Here, πold\n",
      "θ\n",
      "and V old\n",
      "ϕ\n",
      "is used for sampling and τ ′ is\n",
      "session trajectory. We then combine these into the\n",
      "unified RL loss:\n",
      "\n",
      "=>\n",
      " LRL(θ, ϕ) = Lpolicy(θ) + η · Lvalue(ϕ)\n",
      "(8)\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " where η is the coefficient of the value objective.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 4.3\n",
      "Selector\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " The Selector is an LLM agent that takes two inputs:\n",
      "a scholar query and a research paper (including its\n",
      "title and abstract). It generates two outputs: (1) a\n",
      "single decision token d, either \"True\" or \"False\",\n",
      "indicating whether the paper satisfies the query,\n",
      "\n",
      "=>\n",
      " 6\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " and (2) a rationale r = (r1, r2, ..., rm) containing\n",
      "m tokens that support this decision. The rationale\n",
      "serves two purposes: enhancing decision accuracy\n",
      "by jointly training the model to generate decisions\n",
      "and explanations, and improving user trust by pro-\n",
      "viding the reasoning in PaSa application.\n",
      "To optimize training efficiency for the Crawler,\n",
      "the decision token is presented before the ratio-\n",
      "nale, allowing the Selector to act as a single-token\n",
      "reward model during the Crawler training. Addi-\n",
      "tionally, the token probability of the decision token\n",
      "can be used to rank search results. At last, as shown\n",
      "in Table 7, the order of the decision and rationale\n",
      "does not affect the Selector’s performance.\n",
      "We perform imitation learning to optimize the\n",
      "Selector. See Appendix B for training data collec-\n",
      "tion and training details.\n",
      "\n",
      "=>\n",
      " 5\n",
      "Experiments\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 5.1\n",
      "Experimental Setting\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " We sequentially trained the Selector and Crawler,\n",
      "both based on the Qwen2.5-7b (Yang et al., 2024),\n",
      "to develop the final agent, referred to as PaSa-7b.\n",
      "\n",
      "=>\n",
      " Selector\n",
      "The Selector was fine-tuned using the\n",
      "training dataset described in Appendix B. We con-\n",
      "ducted supervised fine-tuning for one epoch with\n",
      "a learning rate of 1e-5 and a batch size of 4. The\n",
      "training runs on 8 NVIDIA-H100 GPUs.\n",
      "\n",
      "=>\n",
      " Crawler\n",
      "The training process involves two\n",
      "stages. First, we perform imitation learning for\n",
      "1 epoch on 12,989 training data with a learning\n",
      "rate of 1e-5 and batch size of 4 per device, using\n",
      "8 NVIDIA H100 GPUs. In the second stage, we\n",
      "apply PPO training. To ensure stability, we first\n",
      "freeze the policy model and train the value model,\n",
      "followed by co-training both the policy and value\n",
      "models. The hyperparameters used during the train-\n",
      "ing process are listed in the Table 4.\n",
      "During imitation learning, the model encoun-\n",
      "ters 5,000 queries, while during the RL training\n",
      "phase, the model processes a total of 16,000 queries.\n",
      "For more details please refer to Appendix A.1 for\n",
      "the imitation learning data construction and Ap-\n",
      "pendix A.2 for the PPO training data sampling.\n",
      "\n",
      "=>\n",
      " Implementation of [Search]\n",
      "This function uti-\n",
      "lizes the LLM to predict a query based on the\n",
      "context, and then calls Google7 with the param-\n",
      "eters site:arxiv.org and before:query_date,\n",
      "\n",
      "=>\n",
      " 7Accessed via the Google Search API provided by https:\n",
      "//serper.dev.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Name\n",
      "Value\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " α\n",
      "(Equation 1)\n",
      "1.5\n",
      "c([Search])\n",
      "(Equation 1)\n",
      "0.1\n",
      "c([Expand])\n",
      "(Equation 1)\n",
      "0.1\n",
      "c([Stop])\n",
      "(Equation 1)\n",
      "0.0\n",
      "γ0\n",
      "(Equation 3)\n",
      "1.0\n",
      "γ1\n",
      "(Equation 3)\n",
      "0.1\n",
      "β\n",
      "(Equation 3)\n",
      "0.1\n",
      "ϵ\n",
      "(Equation 5, Equation 6)\n",
      "0.2\n",
      "η\n",
      "(Equation 8)\n",
      "10\n",
      "learning rate\n",
      "1e-6\n",
      "epoch per step\n",
      "2\n",
      "forward batch size\n",
      "1\n",
      "accumulate batch size\n",
      "16\n",
      "NVIDIA H100 GPU\n",
      "16\n",
      "policy freezing step\n",
      "50\n",
      "total step\n",
      "250\n",
      "\n",
      "=>\n",
      " Table 4: The hyperparameters used in PPO training.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " restricting search results by source and publication\n",
      "time.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Paper Management\n",
      "We developed a database to\n",
      "manage and restore research papers. PaSa retrieves\n",
      "paper information from the database. If no match-\n",
      "ing record is found, we use ar5iv8 to obtain the full\n",
      "paper content, including citations, and then parse\n",
      "this data and store it in the database.\n",
      "\n",
      "=>\n",
      " 5.2\n",
      "Baselines and Evaluation\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " We evaluate our paper search agent on both the test\n",
      "set of AutoScholarQuery and RealScholarQuery.\n",
      "We compare PaSa-7b against the following base-\n",
      "lines:\n",
      "\n",
      "=>\n",
      " • Google. We use Google to search the query\n",
      "directly, with the same parameter settings in\n",
      "Section 5.1.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " • Google Scholar. Queries are submitted di-\n",
      "rectly to Google Scholar7, with the same pa-\n",
      "rameter settings in Section 5.1.\n",
      "\n",
      "=>\n",
      " • Google with GPT-4o. We first employ GPT-\n",
      "4o to paraphrase the scholar query. The para-\n",
      "phrased query is then searched on Google.\n",
      "\n",
      "=>\n",
      " • ChatGPT. We submit the scholar query to\n",
      "ChatGPT9, powered by search-enabled GPT-\n",
      "4o. Due to the need for manual query submis-\n",
      "\n",
      "=>\n",
      " 8https://ar5iv.org/\n",
      "9https://chatgpt.com\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 7\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Method\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "Recall@100\n",
      "Recall@50\n",
      "Recall@20\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Google\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2015\n",
      "0.1891\n",
      "0.1568\n",
      "Google Scholar\n",
      "-\n",
      "-\n",
      "-\n",
      "0.1130\n",
      "0.0970\n",
      "0.0609\n",
      "Google with GPT-4o\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2683\n",
      "0.2450\n",
      "0.1921\n",
      "ChatGPT\n",
      "-\n",
      "0.0507\n",
      "0.3046\n",
      "-\n",
      "-\n",
      "-\n",
      "GPT-o1\n",
      "-\n",
      "0.0413\n",
      "0.1925\n",
      "-\n",
      "-\n",
      "-\n",
      "PaSa-GPT-4o\n",
      "0.7565\n",
      "0.1457\n",
      "0.3873\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "=>\n",
      " PaSa-7b\n",
      "0.7931\n",
      "0.1448\n",
      "0.4834\n",
      "0.6947\n",
      "0.6334\n",
      "0.5301\n",
      "PaSa-7b-ensemble\n",
      "0.8265\n",
      "0.1410\n",
      "0.4985\n",
      "0.7099\n",
      "0.6386\n",
      "0.5326\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Table 5: Results on AutoScholarQuery test set.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Method\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "Recall@100\n",
      "Recall@50\n",
      "Recall@20\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Google\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2535\n",
      "0.2342\n",
      "0.1834\n",
      "Google Scholar\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2809\n",
      "0.2155\n",
      "0.1514\n",
      "Google with GPT-4o\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2946\n",
      "0.2573\n",
      "0.2020\n",
      "ChatGPT\n",
      "-\n",
      "0.2280\n",
      "0.2007\n",
      "-\n",
      "-\n",
      "-\n",
      "GPT-o1\n",
      "-\n",
      "0.058\n",
      "0.0134\n",
      "-\n",
      "-\n",
      "-\n",
      "PaSa-GPT-4o\n",
      "0.5494\n",
      "0.4721\n",
      "0.3075\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "=>\n",
      " PaSa-7b\n",
      "0.7071\n",
      "0.5146\n",
      "0.6111\n",
      "0.6929\n",
      "0.6563\n",
      "0.5798\n",
      "PaSa-7b-ensemble\n",
      "0.7503\n",
      "0.4938\n",
      "0.6488\n",
      "0.7281\n",
      "0.6877\n",
      "0.5986\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Table 6: Results on RealScholarQuery.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " sion, we evaluate only 100 randomly sampled\n",
      "instances from the AutoScholarQuery test set.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " • GPT-o1.\n",
      "Prompt GPT-o1 to process the\n",
      "scholar query.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " • PaSa-GPT-4o. Prompt GPT-4o within the\n",
      "PaSa framework.\n",
      "It can perform multiple\n",
      "searches, paper reading, and citation network\n",
      "crawling.\n",
      "\n",
      "=>\n",
      " We carefully designed prompts for all baselines\n",
      "and they are shown in Appendix E.1.\n",
      "As shown in Figure 2, the crawling process of\n",
      "PaSa can be visualized as a paper tree. In practice,\n",
      "considering the computational expense, we limit\n",
      "the Crawler’s exploration depth (starting from the\n",
      "user query) to three for both PaSa-7b and PaSa-\n",
      "GPT-4o.\n",
      "For Google-based baselines, we evaluate recall\n",
      "using Recall@20, Recall@50, and Recall@100\n",
      "metrics for the top-20, top-50, and top-100 search\n",
      "results, respectively. For other baselines, we assess\n",
      "precision and recall for the final retrieved papers.\n",
      "Additionally, we compare the crawler’s recall be-\n",
      "tween PaSa-GPT-4o and PaSa-7b.\n",
      "\n",
      "=>\n",
      " 5.3\n",
      "Main results\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " As shown in Table 5, PaSa-7b outperforms all base-\n",
      "lines on AutoScholarQuery test set. Specifically,\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " compared to the strongest baseline, PaSa-GPT-4o,\n",
      "PaSa-7b demonstrates a 9.64% improvement in\n",
      "recall with comparable precision. Moreover, the re-\n",
      "call of the Crawler in PaSa-7b is 3.66% higher than\n",
      "that in PaSa-GPT-4o. When compared to the best\n",
      "Google-based baseline, Google with GPT-4o, PaSa-\n",
      "7b achieves an improvement of 33.80%, 38.83%\n",
      "and 42.64% in Recall@20, Recall@50 and Re-\n",
      "call@100, respectively.\n",
      "\n",
      "=>\n",
      " We observe that using multiple ensembles of\n",
      "Crawler during inference can improve performance.\n",
      "Specifically, running Crawler twice during infer-\n",
      "ence increased the Crawler recall by 3.34% on Au-\n",
      "toScholarQuery, leading to the final recall improve-\n",
      "ment by 1.51%, with precision remaining similar.\n",
      "\n",
      "=>\n",
      " To evaluate PaSa in a more realistic setting, we\n",
      "assess its effectiveness on RealScholarQuery. As\n",
      "illustrated in Table 6, PaSa-7b exhibits a greater\n",
      "advantage in real-world academic search scenar-\n",
      "ios. Compared to PaSa-GPT-4o, PaSa-7b achieves\n",
      "improvements of 30.36% in recall and 4.25% in\n",
      "precision. Against the best Google-based baseline\n",
      "on RealScholarQuery, Google with GPT-4o, PaSa-\n",
      "7b outperforms Google by 37.78%, 39.90%, and\n",
      "39.83% in recall@20, recall@50 and recall@100,\n",
      "respectively. Additionally, the PaSa-7b-ensemble\n",
      "further enhances crawler recall by 4.32%, contribut-\n",
      "ing to an overall 3.52% improvement in the recall\n",
      "\n",
      "=>\n",
      " 8\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " of the entire agent system.\n",
      "As both the final decision-maker and auxiliary\n",
      "reward model in RL training for the Crawler, the\n",
      "performance of the Selector is crucial. To evalu-\n",
      "ate its effectiveness, we collected a dataset of 200\n",
      "query-paper pairs, annotating whether each paper\n",
      "meets the query’s requirements. This dataset serves\n",
      "as the benchmark for evaluating the Selector (see\n",
      "Appendix C for details). We then compared our\n",
      "Selector against GPT-4o (Hurst et al., 2024) and\n",
      "Qwen-2.5-7b (Yang et al., 2024), as shown in Ta-\n",
      "ble 7. The results show that our Selector achieves\n",
      "an F1 score of 85%, outperforming GPT-4o by\n",
      "5% and Qwen-2.5-7b by 30%. Additionally, when\n",
      "compared to a setting where reasoning precedes\n",
      "decision token generation, the performance is com-\n",
      "parable. Lastly, the Selector’s precision reaches\n",
      "95%, confirming its effectiveness as an auxiliary\n",
      "reward model for the Crawler RL training.\n",
      "\n",
      "=>\n",
      " Method\n",
      "Precision\n",
      "Recall\n",
      "F1\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " GPT-4o\n",
      "0.96\n",
      "0.69\n",
      "0.80\n",
      "Qwen-2.5-7b\n",
      "1.0\n",
      "0.38\n",
      "0.55\n",
      "PaSa-7b-Selector\n",
      "0.95\n",
      "0.78\n",
      "0.85\n",
      "PaSa-7b-Selector (Reason First)\n",
      "0.94\n",
      "0.76\n",
      "0.84\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Table 7: Selector Evaluation.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 5.4\n",
      "Ablation study\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " We perform ablation studies in Table 8 to evaluate\n",
      "the individual contributions of exploring citation\n",
      "networks, RL training, and using the Selector as the\n",
      "reward model. The results indicate that removing\n",
      "the [Expand] action from the Crawler leads to a\n",
      "significant drop in the recall: a decrease of 22.98%\n",
      "on AutoScholarQuery and 32.21% on RealScholar-\n",
      "Query. Furthermore, RL training enhances recall\n",
      "by 6.24% on AutoScholarQuery and 19.96% on\n",
      "RealScholarQuery. The RL training curves are de-\n",
      "picted in Figure 3, where the training curves show\n",
      "a steady increase in return with the training steps,\n",
      "eventually converging after 200 steps. Finally, re-\n",
      "moving the Selector as an auxiliary reward model\n",
      "results in a 3.76% recall drop on AutoScholarQuery\n",
      "and a 9.63% drop on RealScholarQuery.\n",
      "We investigate how to control agent behavior by\n",
      "adjusting the rewards in RL training. Experiments\n",
      "are conducted with varying reward coefficients α in\n",
      "Equation 1, and results are presented in Table 9. We\n",
      "report two metrics: crawler recall and crawler ac-\n",
      "tion. The crawler action refers to the total number\n",
      "of [Search] and [Expand] actions throughout the\n",
      "\n",
      "=>\n",
      " Crawler’s entire trajectory. As the reward increases,\n",
      "both crawler recall and crawler action increase, sug-\n",
      "gesting that adjusting rewards in RL training can\n",
      "effectively influence PaSa’s behavior.\n",
      "\n",
      "=>\n",
      " Figure 3: Return and value function loss curves during\n",
      "the PPO training process. The smoothing method of\n",
      "the curve in the figures is the exponential moving av-\n",
      "erage(EMA) formula that aligns with the one used in\n",
      "TensorBoard, and the smoothing weight is set to 0.95.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 6\n",
      "Conclusion\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " In this paper, we introduce PaSa, a novel paper\n",
      "search agent designed to provide comprehensive\n",
      "and accurate results for complex academic queries.\n",
      "PaSa is implemented within the AGILE, a rein-\n",
      "forcement learning framework for LLM agents.\n",
      "To train PaSa, we developed AutoScholarQuery,\n",
      "a dataset of fine-grained academic queries and cor-\n",
      "responding papers drawn from top-tier AI confer-\n",
      "ence publications. To evaluate PaSa in real-world\n",
      "scenarios, we also constructed RealScholarQuery,\n",
      "a dataset of actual academic queries paired with\n",
      "annotated papers. Our experimental results demon-\n",
      "strate that PaSa outperforms all baselines, including\n",
      "Google, Google Scholar, and Google with GPT-4o,\n",
      "ChatGPT, GPT-o1, and PaSa-GPT-4o. In partic-\n",
      "ular, PaSa-7B surpasses Google with GPT-4o by\n",
      "37.78% in recall@20 and 39.90% in recall@50,\n",
      "while also exceeding PaSa-GPT-4o by 30.36% in\n",
      "recall and 4.25% in precision. These findings un-\n",
      "derscore PaSa significantly improves the efficiency\n",
      "and accuracy of academic search.\n",
      "\n",
      "=>\n",
      " 9\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Method\n",
      "AutoScholarQuery\n",
      "RealScholarQuery\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "Crawler Recall\n",
      "Precision\n",
      "Recall\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " w/o [Expand]\n",
      "0.3355\n",
      "0.1445\n",
      "0.2536\n",
      "0.3359\n",
      "0.6738\n",
      "0.2890\n",
      "w/o RL training\n",
      "0.6556\n",
      "0.1476\n",
      "0.4210\n",
      "0.4847\n",
      "0.5155\n",
      "0.4115\n",
      "w/o Selector as RM\n",
      "0.7041\n",
      "0.1535\n",
      "0.4458\n",
      "0.5994\n",
      "0.5489\n",
      "0.5148\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " PaSa-7b\n",
      "0.7931\n",
      "0.1448\n",
      "0.4834\n",
      "0.7071\n",
      "0.5146\n",
      "0.6111\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Table 8: Ablation study results on AutoScholarQuery test set and RealScholarQuery.\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " α\n",
      "Crawler Recall\n",
      "Crawler Actions\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " 0.5\n",
      "0.7227\n",
      "175.9\n",
      "1.0\n",
      "0.7708\n",
      "319.8\n",
      "1.5\n",
      "0.7931\n",
      "382.4\n",
      "2.0\n",
      "0.8063\n",
      "785.5\n",
      "\n",
      "********* skipped\n",
      "=>\n",
      " Table 9: Performance of the Crawler trained on different\n",
      "reward coefficient α on AutoScholarQuery test set.\n",
      "\n",
      "********* skipped\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def get_page_span(blocks):\n",
    "    abstract_idx = None\n",
    "    for i in range(len(blocks)):\n",
    "        if re.search(\"^Abstract\", blocks[i], re.IGNORECASE):\n",
    "            abstract_idx = i\n",
    "            break\n",
    "    \n",
    "    references_idx = None\n",
    "    for i in range(len(blocks)-1, -1, -1):\n",
    "        if re.search(\"^References\", blocks[i], re.IGNORECASE):\n",
    "            references_idx = i\n",
    "            break\n",
    "    \n",
    "    return abstract_idx, references_idx\n",
    "            \n",
    "def clean_block(block: str) -> str:\n",
    "    if re.search(\"^figure\", block, re.IGNORECASE):\n",
    "        return \"\"\n",
    "    \n",
    "    MIN_BLOCK_LENGTH = 20 #words\n",
    "    single_line_block = block.replace(\"\\n\", \" \")\n",
    "    single_line_block = re.sub(r\"-?\\d+(?:\\.\\d+)?\", \" \", single_line_block)\n",
    "    if len(single_line_block.split()) < MIN_BLOCK_LENGTH:\n",
    "        return \"\"\n",
    "\n",
    "    return block\n",
    "\n",
    "def clean_blocks(blocks: list[str]):\n",
    "    abstract_idx, references_idx = get_page_span(blocks)\n",
    "    print(abstract_idx, references_idx)\n",
    "\n",
    "    assert abstract_idx is not None and references_idx is not None\n",
    "    \n",
    "    blocks = blocks[abstract_idx+1: references_idx] \n",
    "    cleaned_blocks = []\n",
    "    for block in blocks:\n",
    "        print(\"=>\\n\", block)\n",
    "        block = clean_block(block)\n",
    "        if block:\n",
    "            cleaned_blocks.append(block)\n",
    "        else:\n",
    "            print(\"********* skipped\")\n",
    "    \n",
    "    return cleaned_blocks\n",
    "\n",
    "cleaned_blocks = clean_blocks(doc_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>\n",
      "We introduce PaSa, an advanced Paper Search\n",
      "agent powered by large language models. PaSa\n",
      "can autonomously make a series of decisions,\n",
      "including invoking search tools, reading pa-\n",
      "pers, and selecting relevant references, to ul-\n",
      "timately obtain comprehensive and accurate\n",
      "results for complex scholarly queries. We op-\n",
      "timize PaSa using reinforcement learning with\n",
      "a synthetic dataset, AutoScholarQuery, which\n",
      "includes 35k fine-grained academic queries and\n",
      "corresponding papers sourced from top-tier AI\n",
      "conference publications. Additionally, we de-\n",
      "velop RealScholarQuery, a benchmark collect-\n",
      "ing real-world academic queries to assess PaSa\n",
      "performance in more realistic scenarios. De-\n",
      "spite being trained on synthetic data, PaSa sig-\n",
      "nificantly outperforms existing baselines on\n",
      "RealScholarQuery, including Google, Google\n",
      "Scholar, Google with GPT-4 for paraphrased\n",
      "queries, chatGPT (search-enabled GPT-4o),\n",
      "GPT-o1, and PaSa-GPT-4o (PaSa implemented\n",
      "by prompting GPT-4o). Notably, PaSa-7B sur-\n",
      "passes the best Google-based baseline, Google\n",
      "with GPT-4o, by 37.78% in recall@20 and\n",
      "39.90% in recall@50. It also exceeds PaSa-\n",
      "GPT-4o by 30.36% in recall and 4.25% in pre-\n",
      "cision. Model, datasets, and code are available\n",
      "at https://github.com/bytedance/pasa.\n",
      "\n",
      "==>\n",
      "Academic paper search lies at the core of research\n",
      "yet represents a particularly challenging informa-\n",
      "tion retrieval task. It requires long-tail special-\n",
      "ized knowledge, comprehensive survey-level cover-\n",
      "age, and the ability to address fine-grained queries.\n",
      "For instance, consider the query: \"Which stud-\n",
      "ies have focused on non-stationary reinforcement\n",
      "learning using value-based methods, specifically\n",
      "UCB-based algorithms?\" While widely used aca-\n",
      "demic search systems like Google Scholar are effec-\n",
      "tive for general queries, they often fall short when\n",
      "addressing these complex queries (Gusenbauer and\n",
      "Haddaway, 2020). Consequently, researchers fre-\n",
      "quently spend substantial time conducting litera-\n",
      "ture surveys (Kingsley et al., 2011; Gusenbauer\n",
      "and Haddaway, 2021).\n",
      "\n",
      "==>\n",
      "The advancements in large language models\n",
      "(LLMs) (OpenAI, 2023; Anthropic, 2024; Gemini,\n",
      "2023; Yang et al., 2024) have inspired numerous\n",
      "studies leveraging LLMs to enhance information\n",
      "retrieval, particularly by refining or reformulating\n",
      "search queries to improve retrieval quality (Alaofi\n",
      "et al., 2023; Li et al., 2023; Ma et al., 2023; Peng\n",
      "et al., 2024). In academic search, however, the\n",
      "process goes beyond simple retrieval. Human re-\n",
      "searchers not only use search tools, but also engage\n",
      "in deeper activities, such as reading relevant papers\n",
      "and checking citations, to perform comprehensive\n",
      "and accurate literature surveys.\n",
      "\n",
      "==>\n",
      "In this paper, we introduce PaSa, a novel paper\n",
      "search agent designed to mimic human behavior\n",
      "for comprehensive and accurate academic paper\n",
      "searches. As illustrated in Figure 1, PaSa con-\n",
      "sists of two LLM agents: the Crawler and the Se-\n",
      "lector. For a given user query, the Crawler can\n",
      "autonomously collect relevant papers by utilizing\n",
      "search tools or extracting citations from the current\n",
      "paper, which are then added to a growing paper\n",
      "queue. The Crawler iteratively processes each pa-\n",
      "per in the paper queue, navigating citation networks\n",
      "to discover increasingly relevant papers. The Selec-\n",
      "tor carefully reads each paper in the paper queue to\n",
      "determine whether it meets the requirements of the\n",
      "user query. We optimize PaSa within the AGILE, a\n",
      "reinforcement learning (RL) framework for LLM\n",
      "agents (Feng et al., 2024).\n",
      "Effective training requires high-quality academic\n",
      "search data. Fortunately, human scientists have al-\n",
      "ready created a vast amount of high-quality aca-\n",
      "demic papers, which contain extensive surveys on\n",
      "a wide range of research topics. We build a syn-\n",
      "thetic but high-quality academic search dataset,\n",
      "AutoScholarQuery, which collects fine-grained\n",
      "scholar queries and their corresponding relevant\n",
      "papers from the related work sections of papers\n",
      "published at ICLR 2023 1, ICML 2023 2, NeurIPS\n",
      "2023 3, ACL 2024 4, and CVPR 2024 5.\n",
      "Au-\n",
      "toScholarQuery includes 33,511 / 1,000 / 1,000\n",
      "query-paper pairs in the training / development /\n",
      "test split.\n",
      "\n",
      "==>\n",
      "Although AutoScholarQuery only provides\n",
      "query and paper answers, without demonstrating\n",
      "the path by which scientists collect the papers, we\n",
      "can utilize them to perform RL training to improve\n",
      "PaSa. In addition, we design a new session-level\n",
      "PPO (Proximal Policy Optimization (Schulman\n",
      "et al., 2017)) training method to address the unique\n",
      "challenges of the paper search task: 1) sparse re-\n",
      "ward: The papers in AutoScholarQuery are col-\n",
      "lected via citations, making it a smaller subset of\n",
      "the actual qualified paper set. 2) long trajectories:\n",
      "The complete trajectory of the Crawler may involve\n",
      "hundreds of papers, which is too long to directly\n",
      "input into the LLM context.\n",
      "\n",
      "==>\n",
      "To evaluate PaSa, besides the test set of Au-\n",
      "toScholarQuery, we also develop a benchmark, Re-\n",
      "alScholarQuery. It contains 50 real-world academic\n",
      "queries with annotated relevant papers, to assess\n",
      "PaSa in real-world scenarios. We compare PaSa\n",
      "with several baselines including Google, Google\n",
      "Scholar, Google paired with GPT-4o for para-\n",
      "phrased queries, chatGPT (search-enabled GPT-\n",
      "4o), GPT-o1 and PaSa-GPT-4o (PaSa agent real-\n",
      "ized by prompting GPT-4o). Our experiments show\n",
      "that PaSa-7b significantly outperforms all baselines.\n",
      "Specifically, for AutoScholarQuery test set, PaSa-\n",
      "7b achieves a 34.05% improvement in Recall@20\n",
      "and a 39.36% improvement in Recall@50 com-\n",
      "pared to Google with GPT-4o, the strongest Google-\n",
      "based baseline. PaSa-7b surpasses PaSa-GPT-4o\n",
      "by 11.12% in recall, with similar precision. For\n",
      "RealScholarQuery, PaSa-7b outperforms Google\n",
      "with GPT-4o by 37.78% in Recall@20 and 39.90%\n",
      "in Recall@50. PaSa-7b surpasses PaSa-GPT-4o by\n",
      "30.36% in recall and 4.25% in precision.\n",
      "\n",
      "==>\n",
      "• We introduce PaSa, a comprehensive and accu-\n",
      "rate paper search agent that can autonomously\n",
      "use online search tools, read entire papers, and\n",
      "navigate citation networks.\n",
      "\n",
      "==>\n",
      "• Although PaSa is trained solely on synthetic\n",
      "data, it achieves remarkable real-world perfor-\n",
      "mance. Experiments demonstrate that PaSa,\n",
      "built on 7B LLM, significantly outperforms\n",
      "all baselines, including GPT-4 agent, Google-\n",
      "based search, and chatGPT.\n",
      "\n",
      "==>\n",
      "LLMs in Scientific Discovery\n",
      "LLMs have been\n",
      "applied across various stages of scientific discov-\n",
      "ery (Van Noorden and Perkel, 2023; Lu et al., 2024;\n",
      "Messeri and Crockett, 2024; Liao et al., 2024), such\n",
      "as brainstorming ideas (Girotra et al., 2023; Wang\n",
      "et al., 2024a; Baek et al., 2024), designing exper-\n",
      "iments (M. Bran et al., 2024), writing code (Xu\n",
      "et al., 2022), and generating research papers (Shao\n",
      "et al., 2024; Agarwal et al., 2024; Wang et al.,\n",
      "2024b). One of the most fundamental yet criti-\n",
      "cal stages in research is conducting academic sur-\n",
      "veys. Despite its importance, current tools like\n",
      "Google Scholar are often insufficient, leading re-\n",
      "searchers to spend considerable time on literature\n",
      "review tasks (Kingsley et al., 2011; Gusenbauer\n",
      "and Haddaway, 2021, 2020). This challenge moti-\n",
      "vates us to develop PaSa, an LLM agent designed\n",
      "to autonomously and comprehensively assist re-\n",
      "searchers in collecting relevant research papers for\n",
      "complex scholarly queries.\n",
      "\n",
      "==>\n",
      "LLM Agents\n",
      "LLM Agents combine LLMs with\n",
      "memory, tool use, and planning, enabling them to\n",
      "perform more complex tasks such as personal copi-\n",
      "lots (Stratton, 2024), travel planning (Gundawar\n",
      "et al., 2024), web operations (Deng et al., 2024),\n",
      "software development (Qian et al., 2023), and sci-\n",
      "entific experimentation (Bran et al., 2023). In ad-\n",
      "dition to realizing LLM Agents through prompt\n",
      "engineering (Park et al., 2023; Yao et al., 2023;\n",
      "Shinn et al., 2024; Chen et al., 2023), recent re-\n",
      "search has focused on optimizing and training these\n",
      "agents (Feng et al., 2024; Putta et al., 2024; Liu\n",
      "\n",
      "==>\n",
      "et al., 2023). Among these efforts, AGILE (Feng\n",
      "et al., 2024), a reinforcement learning framework\n",
      "for LLM agents, allows the joint optimization of all\n",
      "agent skills in an end-to-end manner. In our work,\n",
      "we adopt the AGILE framework to implement PaSa.\n",
      "Specifically, we design a novel session-level PPO\n",
      "algorithm to address the unique challenges of the\n",
      "paper search task, including sparse rewards and\n",
      "long trajectories.\n",
      "\n",
      "==>\n",
      "AutoScholarQuery is a synthetic but high-quality\n",
      "dataset of academic queries and related papers,\n",
      "specifically curated for the AI field.\n",
      "To construct AutoScholarQuery, we began by\n",
      "collecting all papers published at ICLR 2023,\n",
      "ICML 2023, NeurIPS 2023, ACL 2024, and CVPR\n",
      "2024. For the Related Work section of each paper,\n",
      "we prompted GPT-4o (Hurst et al., 2024) to gener-\n",
      "ate scholarly queries, where the answers to these\n",
      "queries correspond to the references cited in the\n",
      "Related Work section. The prompt used is shown\n",
      "in Appendix E.1. For each query, we retained only\n",
      "the papers that could be retrieved on arXiv6, using\n",
      "their arxiv_id as the unique article identifier in the\n",
      "dataset. We adopt the publication date of the source\n",
      "paper as the query date. During both training and\n",
      "testing, we only considered papers published prior\n",
      "to the query date.\n",
      "The final AutoScholarQuery dataset comprises\n",
      "33,551, 1,000, and 1,000 instances in the train-\n",
      "ing, development, and testing splits, respectively.\n",
      "Each instance consists of a query, the associated\n",
      "paper set, and the query date, with queries in each\n",
      "split derived from distinct source papers. Table 1\n",
      "provides illustrative examples from AutoScholar-\n",
      "Query, while additional dataset statistics are sum-\n",
      "marized in Table 2.\n",
      "To evaluate the quality of AutoScholarQuery,\n",
      "we sampled 100 query-paper pairs and assessed\n",
      "the rationality and relevance of each query and\n",
      "the corresponding paper. A qualified query should\n",
      "be meaningful and unambiguous. A qualified pa-\n",
      "per should match the requirements of the scholarly\n",
      "query. The author manually reviewed each pair,\n",
      "determining that 94.0% of the queries were qual-\n",
      "ified. Among these qualified queries, 93.7% had\n",
      "corresponding papers that were deemed relevant\n",
      "and appropriate.\n",
      "\n",
      "==>\n",
      "Query: Could you provide me some studies that proposed hierarchical neural models to capture spatiotemporal features in sign\n",
      "videos?\n",
      "Query Date: 2023-05-02\n",
      "Answer Papers:\n",
      "[1] TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation\n",
      "[2] Sign Language Translation with Hierarchical Spatio-Temporal Graph Neural Network\n",
      "Source: SLTUnet: A Simple Unified Model for Sign Language Translation, ICLR 2023\n",
      "Query: Which studies have focused on nonstationary RL using value-based methods, specifically Upper Confidence Bound (UCB)\n",
      "based algorithms?\n",
      "Query Date: 2023-08-10\n",
      "Answer Papers:\n",
      "[1] Reinforcement Learning for Non-Stationary Markov Decision Processes: The Blessing of (More) Optimism\n",
      "[2] Efficient Learning in Non-Stationary Linear Markov Decision Processes\n",
      "[3] Nonstationary Reinforcement Learning with Linear Function Approximation\n",
      "Source: Provably Efficient Algorithm for Nonstationary Low-Rank MDPs, NeurIPS 2023\n",
      "Query: Which studies have been conducted in long-form text generation, specifically in story generation?\n",
      "Query Date: 2024-01-26\n",
      "Answer Papers:\n",
      "[1] Strategies for Structuring Story Generation\n",
      "[2] MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models\n",
      "Source: ProxyQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models, ACL 2024\n",
      "\n",
      "==>\n",
      "Table 2: Statistics of AutoScholarQuery. |P| and |Q|\n",
      "represent the total number of papers and queries col-\n",
      "lected for each conference. Ans(/Q) denotes the aver-\n",
      "age number of answer papers per query. Ans-50 and\n",
      "Ans-90 refers to the 50th and 90th percentiles of answer\n",
      "paper counts per query.\n",
      "\n",
      "==>\n",
      "To evaluate PaSa in more realistic scenarios, we\n",
      "constructed RealScholarQuery, a test dataset con-\n",
      "sisting of 50 real-world research queries. After\n",
      "launching the demo of PaSa, we invited several AI\n",
      "researchers to use the system. From the queries\n",
      "they provided, we randomly sampled a subset of\n",
      "queries and manually filtered out overly broad top-\n",
      "ics (e.g., \"multi-modal large language models,\"\n",
      "\"video generation\"). Ultimately, we collected 50\n",
      "fine-grained and realistic queries.\n",
      "For each query, we first manually gathered rele-\n",
      "vant papers. Subsequently, we used multiple meth-\n",
      "ods to retrieve additional papers, including PaSa,\n",
      "Google, Google Scholar, ChatGPT (search-enabled\n",
      "GPT-4o), and Google paired with GPT-4o for para-\n",
      "phrased queries. The results from these methods\n",
      "were aggregated into a pool of candidate papers.\n",
      "Finally, professional annotators reviewed all can-\n",
      "didate papers for each query, selecting those that\n",
      "\n",
      "==>\n",
      "met the specific requirements of the query to create\n",
      "the final set of relevant papers. The query date of\n",
      "all instances in RealScholarQuery is 2024-10-01.\n",
      "Table 12 in Appendix D provides examples from\n",
      "RealScholarQuery.\n",
      "\n",
      "==>\n",
      "The annotators included professors from the De-\n",
      "partment of Computer Science at a top-tier univer-\n",
      "sity in China. On average, each query required the\n",
      "annotators to review 76 candidate papers. Given\n",
      "the high cost of the annotations, we completed this\n",
      "process for only 50 instances.\n",
      "\n",
      "==>\n",
      "As illustrated in Figure 1, the PaSa system consists\n",
      "of two LLM agents: Crawler and Selector. The\n",
      "crawler reads the user’s query, generates multiple\n",
      "search queries, and retrieves relevant papers. The\n",
      "retrieved papers are added to a paper queue. The\n",
      "Crawler further processes each paper in the paper\n",
      "queue to identify key citations worth exploring fur-\n",
      "ther, appending any newly relevant papers to the\n",
      "paper list. The selector conducts a thorough review\n",
      "of each paper in the paper list to assess whether it\n",
      "fulfills the user’s query requirements.\n",
      "\n",
      "==>\n",
      "In summary, the Crawler is designed to maxi-\n",
      "mize the recall of relevant papers, whereas the Se-\n",
      "lector emphasizes precision in identifying papers\n",
      "that meet the user’s needs.\n",
      "\n",
      "==>\n",
      "In RL terminology, the Crawler performs a token-\n",
      "level Markov Decision Process (MDP). The ac-\n",
      "tion space A corresponds to the LLM’s vocabulary,\n",
      "where each token represents an action. The LLM\n",
      "functions as the policy model. The agent’s state is\n",
      "defined by the current LLM context and the paper\n",
      "queue. The Crawler operates with three registered\n",
      "functions, as outlined in Table 3. When an ac-\n",
      "tion matches a function name, the corresponding\n",
      "function is executed, further modifying the agent’s\n",
      "state.\n",
      "For example, as Figure 2 shows, the agent begins\n",
      "by receiving a user query, incorporating it into its\n",
      "context, and initiating actions. If the token gener-\n",
      "ated is [Search], the LLM continues to generate a\n",
      "search query, and the agent invokes a search tool to\n",
      "retrieve papers, which are then added to the paper\n",
      "list. If the token is [Expand], the LLM continues\n",
      "to extract a subsection name from the current pa-\n",
      "\n",
      "==>\n",
      "per in its context. The agent subsequently uses a\n",
      "parsing tool to extract all referenced papers within\n",
      "that subsection, adding them to the paper list. If\n",
      "the token is [Stop], the agent resets its context to\n",
      "the user query and information of the next paper\n",
      "in the paper queue. This information includes the\n",
      "title, abstract, and an outline of all sections and\n",
      "subsections.\n",
      "The training process for the Crawler comprises\n",
      "two stages. In the first stage, we generate trajec-\n",
      "tories for a small subset of the training data and\n",
      "then perform imitation learning (see Appendix A.1\n",
      "for details). In the second stage, reinforcement\n",
      "learning is applied. The details of the RL training\n",
      "implementation are described below.\n",
      "\n",
      "==>\n",
      "Reward Design\n",
      "We conduct RL training on the\n",
      "AutoScholarQuery training set, where each in-\n",
      "stance consists of a query q and a corresponding\n",
      "paper set P. Starting with a query q, the Crawler\n",
      "generates a trajectory τ = (s1, a1, · · · , sT , aT ). At\n",
      "each time step t, we denote the current paper queue\n",
      "as Qt. Upon taking action at, the Crawler appends\n",
      "a set of new papers (p1, p2, · · · , pnt) to the paper\n",
      "queue. If at = [Stop], the set is empty.\n",
      "The reward of executing action at in state st is\n",
      "defined as\n",
      "\n",
      "==>\n",
      "where I(q, pi, t) = 1 if pi matches the query q and\n",
      "is not already in Qt, and I(q, pi, t) = 0 otherwise.\n",
      "\n",
      "==>\n",
      "Here, α is a reward coefficient, and c(at) is the cost\n",
      "of action at.\n",
      "The indicator function I(q, pi, t) can be deter-\n",
      "mined by checking if pi belongs to P −Qt. How-\n",
      "ever, it is important to note that the AutoScholar-\n",
      "Query may only include a subset of the ground-\n",
      "truth papers, as citations often emphasize a limited\n",
      "number of key references. If the Crawler receives\n",
      "rewards solely based on matching papers in Au-\n",
      "toScholarQuery, this could lead to sparse rewards\n",
      "during training. To mitigate this, we use the Selec-\n",
      "tor as an auxiliary reward model for the Crawler.\n",
      "The revised definition of I(q, pi, t) is:\n",
      "\n",
      "==>\n",
      "Here Selector(q, pi) = 1 if paper pi is identified\n",
      "as correct to meet the query q by the Selector, and\n",
      "Selector(q, pi) = 0 otherwise.\n",
      "\n",
      "==>\n",
      "RL Training\n",
      "A key challenge in training the\n",
      "Crawler with RL is the significant time required\n",
      "to sample a complete trajectory for a given query.\n",
      "This is due to each [Search] or [Expand] action\n",
      "adding multiple papers to the paper list, resulting\n",
      "in hundreds or even thousands of papers in the final\n",
      "paper queue.\n",
      "To address this issue, we define a session as a\n",
      "sub-trajectory that begins with a session’s initial\n",
      "state and ends with the [Stop] action. We iden-\n",
      "tify two types of session initial states: Sq, which\n",
      "includes only a query, and Sq+p, which consists of\n",
      "both a query and a paper.\n",
      "Formally,\n",
      "we\n",
      "model\n",
      "the\n",
      "Crawler\n",
      "as\n",
      "a\n",
      "policy πθ(at|st).\n",
      "We partition the entire\n",
      "trajectory\n",
      "τ\n",
      "into\n",
      "a\n",
      "sequence\n",
      "of\n",
      "sessions:\n",
      "(τt1:t2−1, τt2:t3−1, · · · ).\n",
      "Each\n",
      "session\n",
      "is\n",
      "τti:ti+1−1\n",
      "=\n",
      "(sti, ati, · · · , sti+1−1, ati+1−1),\n",
      "where the initial state sti is either belonging to\n",
      "type Sq or Sq+p, and the final action ati+1−1 is\n",
      "[STOP].\n",
      "Sampling such a sub-trajectory from these ses-\n",
      "sion initial states is computationally efficient. Dur-\n",
      "ing the PPO training, at time step t ∈[ti, ti+1),\n",
      "we estimate the return in the session using Monte\n",
      "Carlo sampling:\n",
      "\n",
      "==>\n",
      "Here, γ0 is the in-session discount factor, and\n",
      "γ1 is the across-session discount factor.\n",
      "ˆVϕ(·)\n",
      "is the value function model to approximate the\n",
      "state value. After executing at+k, the paper queue\n",
      "is updated to include the newly found papers\n",
      "(p1, p2, · · · , pnt+k). Since the Crawler will subse-\n",
      "quently initiate new sessions to process these addi-\n",
      "tional papers, their associated reward-to-go should\n",
      "be incorporated into the return estimate. In addi-\n",
      "tion, we include a per-token KL penalty term from\n",
      "the learned policy πθ to the initial policy πsft ob-\n",
      "tained through imitation learning at each token to\n",
      "mitigate over-optimization. This term is scaled by\n",
      "the coefficient β.\n",
      "Then the advantage function can be approxi-\n",
      "mated by\n",
      "\n",
      "==>\n",
      "ˆV clip\n",
      "ϕ\n",
      "(st) =\n",
      "clip\n",
      "\u0010\n",
      "ˆVϕ(st), V old\n",
      "ϕ (st) −ϵ, V old\n",
      "ϕ (st) + ϵ\n",
      "\u0011\n",
      ". (7)\n",
      "\n",
      "==>\n",
      "Here, πold\n",
      "θ\n",
      "and V old\n",
      "ϕ\n",
      "is used for sampling and τ ′ is\n",
      "session trajectory. We then combine these into the\n",
      "unified RL loss:\n",
      "\n",
      "==>\n",
      "The Selector is an LLM agent that takes two inputs:\n",
      "a scholar query and a research paper (including its\n",
      "title and abstract). It generates two outputs: (1) a\n",
      "single decision token d, either \"True\" or \"False\",\n",
      "indicating whether the paper satisfies the query,\n",
      "\n",
      "==>\n",
      "and (2) a rationale r = (r1, r2, ..., rm) containing\n",
      "m tokens that support this decision. The rationale\n",
      "serves two purposes: enhancing decision accuracy\n",
      "by jointly training the model to generate decisions\n",
      "and explanations, and improving user trust by pro-\n",
      "viding the reasoning in PaSa application.\n",
      "To optimize training efficiency for the Crawler,\n",
      "the decision token is presented before the ratio-\n",
      "nale, allowing the Selector to act as a single-token\n",
      "reward model during the Crawler training. Addi-\n",
      "tionally, the token probability of the decision token\n",
      "can be used to rank search results. At last, as shown\n",
      "in Table 7, the order of the decision and rationale\n",
      "does not affect the Selector’s performance.\n",
      "We perform imitation learning to optimize the\n",
      "Selector. See Appendix B for training data collec-\n",
      "tion and training details.\n",
      "\n",
      "==>\n",
      "We sequentially trained the Selector and Crawler,\n",
      "both based on the Qwen2.5-7b (Yang et al., 2024),\n",
      "to develop the final agent, referred to as PaSa-7b.\n",
      "\n",
      "==>\n",
      "Selector\n",
      "The Selector was fine-tuned using the\n",
      "training dataset described in Appendix B. We con-\n",
      "ducted supervised fine-tuning for one epoch with\n",
      "a learning rate of 1e-5 and a batch size of 4. The\n",
      "training runs on 8 NVIDIA-H100 GPUs.\n",
      "\n",
      "==>\n",
      "Crawler\n",
      "The training process involves two\n",
      "stages. First, we perform imitation learning for\n",
      "1 epoch on 12,989 training data with a learning\n",
      "rate of 1e-5 and batch size of 4 per device, using\n",
      "8 NVIDIA H100 GPUs. In the second stage, we\n",
      "apply PPO training. To ensure stability, we first\n",
      "freeze the policy model and train the value model,\n",
      "followed by co-training both the policy and value\n",
      "models. The hyperparameters used during the train-\n",
      "ing process are listed in the Table 4.\n",
      "During imitation learning, the model encoun-\n",
      "ters 5,000 queries, while during the RL training\n",
      "phase, the model processes a total of 16,000 queries.\n",
      "For more details please refer to Appendix A.1 for\n",
      "the imitation learning data construction and Ap-\n",
      "pendix A.2 for the PPO training data sampling.\n",
      "\n",
      "==>\n",
      "Implementation of [Search]\n",
      "This function uti-\n",
      "lizes the LLM to predict a query based on the\n",
      "context, and then calls Google7 with the param-\n",
      "eters site:arxiv.org and before:query_date,\n",
      "\n",
      "==>\n",
      "α\n",
      "(Equation 1)\n",
      "1.5\n",
      "c([Search])\n",
      "(Equation 1)\n",
      "0.1\n",
      "c([Expand])\n",
      "(Equation 1)\n",
      "0.1\n",
      "c([Stop])\n",
      "(Equation 1)\n",
      "0.0\n",
      "γ0\n",
      "(Equation 3)\n",
      "1.0\n",
      "γ1\n",
      "(Equation 3)\n",
      "0.1\n",
      "β\n",
      "(Equation 3)\n",
      "0.1\n",
      "ϵ\n",
      "(Equation 5, Equation 6)\n",
      "0.2\n",
      "η\n",
      "(Equation 8)\n",
      "10\n",
      "learning rate\n",
      "1e-6\n",
      "epoch per step\n",
      "2\n",
      "forward batch size\n",
      "1\n",
      "accumulate batch size\n",
      "16\n",
      "NVIDIA H100 GPU\n",
      "16\n",
      "policy freezing step\n",
      "50\n",
      "total step\n",
      "250\n",
      "\n",
      "==>\n",
      "Paper Management\n",
      "We developed a database to\n",
      "manage and restore research papers. PaSa retrieves\n",
      "paper information from the database. If no match-\n",
      "ing record is found, we use ar5iv8 to obtain the full\n",
      "paper content, including citations, and then parse\n",
      "this data and store it in the database.\n",
      "\n",
      "==>\n",
      "We evaluate our paper search agent on both the test\n",
      "set of AutoScholarQuery and RealScholarQuery.\n",
      "We compare PaSa-7b against the following base-\n",
      "lines:\n",
      "\n",
      "==>\n",
      "• Google Scholar. Queries are submitted di-\n",
      "rectly to Google Scholar7, with the same pa-\n",
      "rameter settings in Section 5.1.\n",
      "\n",
      "==>\n",
      "• Google with GPT-4o. We first employ GPT-\n",
      "4o to paraphrase the scholar query. The para-\n",
      "phrased query is then searched on Google.\n",
      "\n",
      "==>\n",
      "• ChatGPT. We submit the scholar query to\n",
      "ChatGPT9, powered by search-enabled GPT-\n",
      "4o. Due to the need for manual query submis-\n",
      "\n",
      "==>\n",
      "Google\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2015\n",
      "0.1891\n",
      "0.1568\n",
      "Google Scholar\n",
      "-\n",
      "-\n",
      "-\n",
      "0.1130\n",
      "0.0970\n",
      "0.0609\n",
      "Google with GPT-4o\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2683\n",
      "0.2450\n",
      "0.1921\n",
      "ChatGPT\n",
      "-\n",
      "0.0507\n",
      "0.3046\n",
      "-\n",
      "-\n",
      "-\n",
      "GPT-o1\n",
      "-\n",
      "0.0413\n",
      "0.1925\n",
      "-\n",
      "-\n",
      "-\n",
      "PaSa-GPT-4o\n",
      "0.7565\n",
      "0.1457\n",
      "0.3873\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "==>\n",
      "Google\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2535\n",
      "0.2342\n",
      "0.1834\n",
      "Google Scholar\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2809\n",
      "0.2155\n",
      "0.1514\n",
      "Google with GPT-4o\n",
      "-\n",
      "-\n",
      "-\n",
      "0.2946\n",
      "0.2573\n",
      "0.2020\n",
      "ChatGPT\n",
      "-\n",
      "0.2280\n",
      "0.2007\n",
      "-\n",
      "-\n",
      "-\n",
      "GPT-o1\n",
      "-\n",
      "0.058\n",
      "0.0134\n",
      "-\n",
      "-\n",
      "-\n",
      "PaSa-GPT-4o\n",
      "0.5494\n",
      "0.4721\n",
      "0.3075\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "==>\n",
      "• PaSa-GPT-4o. Prompt GPT-4o within the\n",
      "PaSa framework.\n",
      "It can perform multiple\n",
      "searches, paper reading, and citation network\n",
      "crawling.\n",
      "\n",
      "==>\n",
      "We carefully designed prompts for all baselines\n",
      "and they are shown in Appendix E.1.\n",
      "As shown in Figure 2, the crawling process of\n",
      "PaSa can be visualized as a paper tree. In practice,\n",
      "considering the computational expense, we limit\n",
      "the Crawler’s exploration depth (starting from the\n",
      "user query) to three for both PaSa-7b and PaSa-\n",
      "GPT-4o.\n",
      "For Google-based baselines, we evaluate recall\n",
      "using Recall@20, Recall@50, and Recall@100\n",
      "metrics for the top-20, top-50, and top-100 search\n",
      "results, respectively. For other baselines, we assess\n",
      "precision and recall for the final retrieved papers.\n",
      "Additionally, we compare the crawler’s recall be-\n",
      "tween PaSa-GPT-4o and PaSa-7b.\n",
      "\n",
      "==>\n",
      "compared to the strongest baseline, PaSa-GPT-4o,\n",
      "PaSa-7b demonstrates a 9.64% improvement in\n",
      "recall with comparable precision. Moreover, the re-\n",
      "call of the Crawler in PaSa-7b is 3.66% higher than\n",
      "that in PaSa-GPT-4o. When compared to the best\n",
      "Google-based baseline, Google with GPT-4o, PaSa-\n",
      "7b achieves an improvement of 33.80%, 38.83%\n",
      "and 42.64% in Recall@20, Recall@50 and Re-\n",
      "call@100, respectively.\n",
      "\n",
      "==>\n",
      "We observe that using multiple ensembles of\n",
      "Crawler during inference can improve performance.\n",
      "Specifically, running Crawler twice during infer-\n",
      "ence increased the Crawler recall by 3.34% on Au-\n",
      "toScholarQuery, leading to the final recall improve-\n",
      "ment by 1.51%, with precision remaining similar.\n",
      "\n",
      "==>\n",
      "To evaluate PaSa in a more realistic setting, we\n",
      "assess its effectiveness on RealScholarQuery. As\n",
      "illustrated in Table 6, PaSa-7b exhibits a greater\n",
      "advantage in real-world academic search scenar-\n",
      "ios. Compared to PaSa-GPT-4o, PaSa-7b achieves\n",
      "improvements of 30.36% in recall and 4.25% in\n",
      "precision. Against the best Google-based baseline\n",
      "on RealScholarQuery, Google with GPT-4o, PaSa-\n",
      "7b outperforms Google by 37.78%, 39.90%, and\n",
      "39.83% in recall@20, recall@50 and recall@100,\n",
      "respectively. Additionally, the PaSa-7b-ensemble\n",
      "further enhances crawler recall by 4.32%, contribut-\n",
      "ing to an overall 3.52% improvement in the recall\n",
      "\n",
      "==>\n",
      "of the entire agent system.\n",
      "As both the final decision-maker and auxiliary\n",
      "reward model in RL training for the Crawler, the\n",
      "performance of the Selector is crucial. To evalu-\n",
      "ate its effectiveness, we collected a dataset of 200\n",
      "query-paper pairs, annotating whether each paper\n",
      "meets the query’s requirements. This dataset serves\n",
      "as the benchmark for evaluating the Selector (see\n",
      "Appendix C for details). We then compared our\n",
      "Selector against GPT-4o (Hurst et al., 2024) and\n",
      "Qwen-2.5-7b (Yang et al., 2024), as shown in Ta-\n",
      "ble 7. The results show that our Selector achieves\n",
      "an F1 score of 85%, outperforming GPT-4o by\n",
      "5% and Qwen-2.5-7b by 30%. Additionally, when\n",
      "compared to a setting where reasoning precedes\n",
      "decision token generation, the performance is com-\n",
      "parable. Lastly, the Selector’s precision reaches\n",
      "95%, confirming its effectiveness as an auxiliary\n",
      "reward model for the Crawler RL training.\n",
      "\n",
      "==>\n",
      "We perform ablation studies in Table 8 to evaluate\n",
      "the individual contributions of exploring citation\n",
      "networks, RL training, and using the Selector as the\n",
      "reward model. The results indicate that removing\n",
      "the [Expand] action from the Crawler leads to a\n",
      "significant drop in the recall: a decrease of 22.98%\n",
      "on AutoScholarQuery and 32.21% on RealScholar-\n",
      "Query. Furthermore, RL training enhances recall\n",
      "by 6.24% on AutoScholarQuery and 19.96% on\n",
      "RealScholarQuery. The RL training curves are de-\n",
      "picted in Figure 3, where the training curves show\n",
      "a steady increase in return with the training steps,\n",
      "eventually converging after 200 steps. Finally, re-\n",
      "moving the Selector as an auxiliary reward model\n",
      "results in a 3.76% recall drop on AutoScholarQuery\n",
      "and a 9.63% drop on RealScholarQuery.\n",
      "We investigate how to control agent behavior by\n",
      "adjusting the rewards in RL training. Experiments\n",
      "are conducted with varying reward coefficients α in\n",
      "Equation 1, and results are presented in Table 9. We\n",
      "report two metrics: crawler recall and crawler ac-\n",
      "tion. The crawler action refers to the total number\n",
      "of [Search] and [Expand] actions throughout the\n",
      "\n",
      "==>\n",
      "Crawler’s entire trajectory. As the reward increases,\n",
      "both crawler recall and crawler action increase, sug-\n",
      "gesting that adjusting rewards in RL training can\n",
      "effectively influence PaSa’s behavior.\n",
      "\n",
      "==>\n",
      "In this paper, we introduce PaSa, a novel paper\n",
      "search agent designed to provide comprehensive\n",
      "and accurate results for complex academic queries.\n",
      "PaSa is implemented within the AGILE, a rein-\n",
      "forcement learning framework for LLM agents.\n",
      "To train PaSa, we developed AutoScholarQuery,\n",
      "a dataset of fine-grained academic queries and cor-\n",
      "responding papers drawn from top-tier AI confer-\n",
      "ence publications. To evaluate PaSa in real-world\n",
      "scenarios, we also constructed RealScholarQuery,\n",
      "a dataset of actual academic queries paired with\n",
      "annotated papers. Our experimental results demon-\n",
      "strate that PaSa outperforms all baselines, including\n",
      "Google, Google Scholar, and Google with GPT-4o,\n",
      "ChatGPT, GPT-o1, and PaSa-GPT-4o. In partic-\n",
      "ular, PaSa-7B surpasses Google with GPT-4o by\n",
      "37.78% in recall@20 and 39.90% in recall@50,\n",
      "while also exceeding PaSa-GPT-4o by 30.36% in\n",
      "recall and 4.25% in precision. These findings un-\n",
      "derscore PaSa significantly improves the efficiency\n",
      "and accuracy of academic search.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for block in cleaned_blocks:\n",
    "    print(\"==>\")\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We introduce PaSa, an advanced Paper Search\n",
      "agent powered by large language models. PaSa\n",
      "can autonomously make a series of decisions,\n",
      "including invoking search tools, reading papers, and selecting relevant references, to ultimately obtain comprehensive and accurate\n",
      "results for complex scholarly queries. We optimize PaSa using reinforcement learning with\n",
      "a synthetic dataset, AutoScholarQuery, which\n",
      "includes 35k fine-grained academic queries and\n",
      "corresponding papers sourced from top-tier AI\n",
      "conference publications. Additionally, we develop RealScholarQuery, a benchmark collecting real-world academic queries to assess PaSa\n",
      "performance in more realistic scenarios. Despite being trained on synthetic data, PaSa significantly outperforms existing baselines on\n",
      "RealScholarQuery, including Google, Google\n",
      "Scholar, Google with GPT-4 for paraphrased\n",
      "queries, chatGPT (search-enabled GPT-4o),\n",
      "GPT-o1, and PaSa-GPT-4o (PaSa implemented\n",
      "by prompting GPT-4o). Notably, PaSa-7B surpasses the best Google-based baseline, Google\n",
      "with GPT-4o, by 37.78% in recall@20 and\n",
      "39.90% in recall@50. It also exceeds PaSaGPT-4o by 30.36% in recall and 4.25% in precision. Model, datasets, and code are available\n",
      "at https://github.com/bytedance/pasa.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(\"-\\n\", \"\", cleaned_blocks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "a = defaultdict(lambda: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "nltk.data.path.append(\"/Users/harshit/nltk_data\")\n",
    "\n",
    "# Download the punkt tokenizer if you haven't already\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def split_into_paragraphs(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences = [re.sub(\"\\n\", \" \", sentence) for sentence in sentences]\n",
    "    \n",
    "    # Group sentences into paragraphs of 2 sentences each\n",
    "    paragraphs = [' '.join(sentences[i:i+2]) for i in range(0, len(sentences), 2)]\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "sentences = split_into_paragraphs(page_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# Define your desired output structure\n",
    "class Datasets(BaseModel):\n",
    "    dataset_names: list[str] = Field(description = \"\"\"Names of datasets mentioned \n",
    "                                     in the text which are used by ML model / algorithm for \n",
    "                                     training.\"\"\")\n",
    "    algorithms: list[str] = Field(description = \"\"\"Names of algorithms mentioned \n",
    "                                     in the text which are used by ML model / algorithm for \n",
    "                                     training / validation \"\"\")\n",
    "\n",
    "# Patch the OpenAI client\n",
    "client1 = instructor.from_openai(OpenAI())\n",
    "\n",
    "text = \"\"\"In order to perform a controlled evaluation, for this\n",
    "experiment we generate preference pairs over generations using a pre-trained sentiment classifier,\n",
    "where p(positive | x, yw) > p(positive | x, yl). For SFT, we fine-tune GPT-2-large until convergence\n",
    "on reviews from the train split of the IMDB dataset (further details in App C.1)\"\"\"\n",
    "\n",
    "# Extract structured data from natural language\n",
    "def get_response1(text):\n",
    "    return client1.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_model=Datasets,\n",
    "        messages=[\n",
    "            {\"role\": \"system\",\n",
    "            \"content\": \"\"\"You're a powerful language model that has been specialized for NER where entities are datasets in the domain of Machine Learning / AI.\n",
    "            Extract the names of datasets mentioned in the given text\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": text}],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshit/Documents/Projects/paper-dots-v2/backend/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# Define your desired output structure\n",
    "class Datasets(BaseModel):\n",
    "    datasets: list[str] = Field(description = \"\"\"Names of datasets mentioned \n",
    "                                     in the text which are used by ML model / algorithm for \n",
    "                                     training.\"\"\")\n",
    "    methods: list[str] = Field(description = \"\"\"Names of algorithms / methods mentioned \n",
    "                                     in the text\"\"\")\n",
    "\n",
    "# Patch the OpenAI client\n",
    "client2 = instructor.from_gemini(\n",
    "    client=genai.GenerativeModel(\n",
    "        model_name=\"models/gemini-1.5-flash-latest\",\n",
    "    ),\n",
    "    mode=instructor.Mode.GEMINI_JSON,\n",
    ")\n",
    "\n",
    "text = \"\"\"In order to perform a controlled evaluation, for this\n",
    "experiment we generate preference pairs over generations using a pre-trained sentiment classifier,\n",
    "where p(positive | x, yw) > p(positive | x, yl). For SFT, we fine-tune GPT-2-large until convergence\n",
    "on reviews from the train split of the IMDB dataset (further details in App C.1)\"\"\"\n",
    "\n",
    "# Extract structured data from natural language\n",
    "def get_response2(text):\n",
    "    return client2.messages.create(\n",
    "    messages=[\n",
    "            {\"role\": \"system\",\n",
    "            \"content\": \"\"\"You're a powerful language model that has been specialized for Named Entity Recognition.\n",
    "            The possible entities are (1) dataset (2) algorithms / methods mentioned in the text.\n",
    "            Extract the names of datasets and algorithms mentioned in the given text\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": text}],\n",
    "    response_model=Datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genai.GenerativeModel(\n",
       "    model_name='models/gemini-1.5-flash-latest',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=None,\n",
       "    system_instruction=None,\n",
       "    cached_content=None\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client2.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets=[] methods=['Convolutional Neural Networks (CNN)', 'Faster R-CNN', 'Mask R-CNN', 'Graph Convolutional Networks (GCN)']\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    responses = list(executor.map(get_response2, cleaned_blocks[3:4]))\n",
    "    \n",
    "for res in responses:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document AI, or Document Intelligence1, is a relatively new re-\n",
      "search topic that refers techniques for automatically reading, under-\n",
      "standing, and analyzing business documents. Business documents\n",
      "are files that provide details related to a company’s internal and\n",
      "external transactions, which are shown in Figure 1. They may be\n",
      "digital-born, occurring as electronic files, or they may be in scanned\n",
      "form that comes from written or printed on paper. Some common\n",
      "examples of business documents include purchase orders, financial\n",
      "reports, business emails, sales agreements, vendor contracts, letters,\n",
      "invoices, receipts, resumes, and many others. Business documents\n",
      "are critical to a company’s efficiency and productivity. The exact\n",
      "format of a business document may vary, but the information is\n",
      "usually presented in natural language and can be organized in a\n",
      "variety of ways from plain text, multi-column layouts, and a wide\n",
      "variety of tables/forms/figures. Understanding business documents\n",
      "is a very challenging task due to the diversity of layouts and formats,\n",
      "poor quality of scanned document images as well as the complexity\n",
      "of template structures.\n",
      "Nowadays, many companies extract data from business docu-\n",
      "ments through manual efforts that are time-consuming and expen-\n",
      "sive, meanwhile requiring manual customization or configuration.\n",
      "Rules and workflows for each type of document often need to be\n",
      "hard-coded and updated with changes to the specific format or\n",
      "when dealing with multiple formats. To address these problems,\n",
      "document AI models and algorithms are designed to automatically\n",
      "classify, extract, and structuralize information from business doc-\n",
      "uments, accelerating automated document processing workflows.\n",
      "Contemporary approaches for document AI are usually built upon\n",
      "deep neural networks from a computer vision perspective or a natu-\n",
      "ral language processing perspective, or a combination of them. Early\n",
      "attempts usually focused on detecting and analyzing certain parts\n",
      "of a document, such as tabular areas. [7] were the first to propose a\n",
      "table detection method for PDF documents based on Convolutional\n",
      "Neural Networks (CNN). After that, [21, 24, 29] also leveraged more\n",
      "advanced Faster R-CNN model [19] or Mask R-CNN model [9] to\n",
      "further improve the accuracy of document layout analysis. In addi-\n",
      "tion, [28] presented an end-to-end, multimodal, fully convolutional\n",
      "network for extracting semantic structures from document images,\n",
      "taking advantage of text embeddings from pre-trained NLP models.\n",
      "More recently, [15] introduced a Graph Convolutional Networks\n",
      "(GCN) based model to combine textual and visual information for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_blocks[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Datasets(dataset_names=['LayoutLM', 'IIT-CDIP Test Collection 1.02'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_openai(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=client.chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extract the names of datasets and algorithms mentioned in the given text.\\n            The possible entities are (1) dataset (2) algorithms / methods mentioned in the text.\\n            \\n            ## Text:\\n            asa\\n            '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Extract the names of datasets and algorithms mentioned in the given text.\n",
    "            The possible entities are (1) dataset (2) algorithms / methods mentioned in the text.\n",
    "            \n",
    "            ## Text:\n",
    "            {}\n",
    "            \"\"\".format(\"asa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
